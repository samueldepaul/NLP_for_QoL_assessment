{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf63bb0",
   "metadata": {},
   "source": [
    "# BINARY CLASSIFICATION PROBLEM:\n",
    "## Does a given phrase contain a QoL indicator?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c77e76",
   "metadata": {},
   "source": [
    "### Installation of required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c4ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.5.7)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=d415b3e7ef144d87a3bec22bfdc6df3bdd489dc7d8d117954fd75e644d635d77\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 5.1.0\n",
      "    Uninstalling chardet-5.1.0:\n",
      "      Successfully uninstalled chardet-5.1.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.20.5 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "sparkmagic 0.20.5 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.0.1 which is incompatible.\n",
      "sphinx 7.0.0 requires docutils<0.20,>=0.18.1, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e38a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting spark-nlp==4.3.2\n",
      "  Downloading spark_nlp-4.3.2-py2.py3-none-any.whl (473 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyspark==3.3.1\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyspark==3.3.1) (0.10.9.5)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845500 sha256=cc5667f77e5bc11836728f6fcbeefccf3d910a4cab963be9a5e1916dcd4f8220\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/0f/f0/3d/517368b8ce80486e84f89f214e0a022554e4ee64969f46279b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: spark-nlp, pyspark\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.3.0\n",
      "    Uninstalling pyspark-3.3.0:\n",
      "      Successfully uninstalled pyspark-3.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-pyspark 1.4.5 requires pyspark==3.3.0, but you have pyspark 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyspark-3.3.1 spark-nlp-4.3.2\n"
     ]
    }
   ],
   "source": [
    "# Install Spark NLP\n",
    "!pip install spark-nlp==4.3.2 pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0aacd",
   "metadata": {},
   "source": [
    "### Import required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ce9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql import functions as fun\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "import sparknlp\n",
    "from sparknlp import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from sparknlp.annotator import WordEmbeddingsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a432f9",
   "metadata": {},
   "source": [
    "### Load testimony data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6ff690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "# Crear una instancia de cliente de S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Especificar el nombre del archivo y el bucket\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'frases.csv'\n",
    "file_name2 = 'frases_test.csv'\n",
    "\n",
    "# Descargar el archivo desde S3 al directorio local\n",
    "s3.download_file(bucket_name, file_name, file_name)\n",
    "s3.download_file(bucket_name, file_name2, file_name2)\n",
    "\n",
    "# Leer el archivo CSV en un dataframe\n",
    "data = pd.read_csv(file_name)\n",
    "unseen = pd.read_csv(file_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48005438",
   "metadata": {},
   "source": [
    "#### Chack data is correctly loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198a1d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enfermedad</th>\n",
       "      <th>Persona</th>\n",
       "      <th>frase</th>\n",
       "      <th>num_ind</th>\n",
       "      <th>indicador</th>\n",
       "      <th>dimension</th>\n",
       "      <th>contiene_indicador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epilepsia</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>Siempre me ha interesado cómo funciona el cere...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epilepsia</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>Me hice profesor de neurofisiología clínica y ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Epilepsia</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>Después, tras sufrir un accidente de ciclismo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epilepsia</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>Fui operado por los hematomas subdurales que t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Epilepsia</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>Tras estudiar la epilepsia durante décadas, me...</td>\n",
       "      <td>1</td>\n",
       "      <td>falta aceptación</td>\n",
       "      <td>Dimensión 8: Mental Health</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Enfermedad           Persona   \n",
       "0  Epilepsia   Primera Persona   \\\n",
       "1  Epilepsia   Primera Persona    \n",
       "2  Epilepsia   Primera Persona    \n",
       "3  Epilepsia   Primera Persona    \n",
       "4  Epilepsia   Primera Persona    \n",
       "\n",
       "                                               frase  num_ind   \n",
       "0  Siempre me ha interesado cómo funciona el cere...        0  \\\n",
       "1  Me hice profesor de neurofisiología clínica y ...        0   \n",
       "2  Después, tras sufrir un accidente de ciclismo ...        0   \n",
       "3  Fui operado por los hematomas subdurales que t...        0   \n",
       "4  Tras estudiar la epilepsia durante décadas, me...        1   \n",
       "\n",
       "          indicador                   dimension  contiene_indicador  \n",
       "0               NaN                         NaN                   0  \n",
       "1               NaN                         NaN                   0  \n",
       "2               NaN                         NaN                   0  \n",
       "3               NaN                         NaN                   0  \n",
       "4  falta aceptación  Dimensión 8: Mental Health                   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73d1c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enfermedad</th>\n",
       "      <th>Persona</th>\n",
       "      <th>frase</th>\n",
       "      <th>num_ind</th>\n",
       "      <th>indicador</th>\n",
       "      <th>dimension</th>\n",
       "      <th>contiene_indicador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cáncer</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>no es algo que ni una madre ni una esposa y un...</td>\n",
       "      <td>1</td>\n",
       "      <td>fortaleza</td>\n",
       "      <td>Dimension 5: Vitality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cáncer</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>así a darle apoyo a uno a la otra persona para...</td>\n",
       "      <td>1</td>\n",
       "      <td>búsqueda apoyo social emocional</td>\n",
       "      <td>Dimension 6: Social Functioning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cáncer</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>y no caer</td>\n",
       "      <td>1</td>\n",
       "      <td>espíritu lucha</td>\n",
       "      <td>Dimension 5: Vitality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cáncer</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>porque es que el cáncer hoy en día es un una c...</td>\n",
       "      <td>1</td>\n",
       "      <td>esperanza</td>\n",
       "      <td>Dimension 5: Vitality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cáncer</td>\n",
       "      <td>Primera Persona</td>\n",
       "      <td>adelante y tener una vida yo en los diez años ...</td>\n",
       "      <td>1</td>\n",
       "      <td>impacto ámbito laboral</td>\n",
       "      <td>Dimension 2: Role Limitations due to Physical ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Enfermedad           Persona   \n",
       "0    Cáncer   Primera Persona   \\\n",
       "1    Cáncer   Primera Persona    \n",
       "2    Cáncer   Primera Persona    \n",
       "3    Cáncer   Primera Persona    \n",
       "4    Cáncer   Primera Persona    \n",
       "\n",
       "                                               frase  num_ind   \n",
       "0  no es algo que ni una madre ni una esposa y un...        1  \\\n",
       "1  así a darle apoyo a uno a la otra persona para...        1   \n",
       "2                                          y no caer        1   \n",
       "3  porque es que el cáncer hoy en día es un una c...        1   \n",
       "4  adelante y tener una vida yo en los diez años ...        1   \n",
       "\n",
       "                         indicador   \n",
       "0                        fortaleza  \\\n",
       "1  búsqueda apoyo social emocional   \n",
       "2                   espíritu lucha   \n",
       "3                        esperanza   \n",
       "4           impacto ámbito laboral   \n",
       "\n",
       "                                           dimension  contiene_indicador  \n",
       "0                              Dimension 5: Vitality                   1  \n",
       "1                    Dimension 6: Social Functioning                   1  \n",
       "2                              Dimension 5: Vitality                   1  \n",
       "3                              Dimension 5: Vitality                   1  \n",
       "4  Dimension 2: Role Limitations due to Physical ...                   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b734cbf",
   "metadata": {},
   "source": [
    "### Data pre-processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad971141",
   "metadata": {},
   "source": [
    "#### Translate testimonies into English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446bf65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduciendo observación 1/910\n",
      "Traduciendo observación 2/910\n",
      "Traduciendo observación 3/910\n",
      "Traduciendo observación 4/910\n",
      "Traduciendo observación 5/910\n",
      "Traduciendo observación 6/910\n",
      "Traduciendo observación 7/910\n",
      "Traduciendo observación 8/910\n",
      "Traduciendo observación 9/910\n",
      "Traduciendo observación 10/910\n",
      "Traduciendo observación 11/910\n",
      "Traduciendo observación 12/910\n",
      "Traduciendo observación 13/910\n",
      "Traduciendo observación 14/910\n",
      "Traduciendo observación 15/910\n",
      "Traduciendo observación 16/910\n",
      "Traduciendo observación 17/910\n",
      "Traduciendo observación 18/910\n",
      "Traduciendo observación 19/910\n",
      "Traduciendo observación 20/910\n",
      "Traduciendo observación 21/910\n",
      "Traduciendo observación 22/910\n",
      "Traduciendo observación 23/910\n",
      "Traduciendo observación 24/910\n",
      "Traduciendo observación 25/910\n",
      "Traduciendo observación 26/910\n",
      "Traduciendo observación 27/910\n",
      "Traduciendo observación 28/910\n",
      "Traduciendo observación 29/910\n",
      "Traduciendo observación 30/910\n",
      "Traduciendo observación 31/910\n",
      "Traduciendo observación 32/910\n",
      "Traduciendo observación 33/910\n",
      "Traduciendo observación 34/910\n",
      "Traduciendo observación 35/910\n",
      "Traduciendo observación 36/910\n",
      "Traduciendo observación 37/910\n",
      "Traduciendo observación 38/910\n",
      "Traduciendo observación 39/910\n",
      "Traduciendo observación 40/910\n",
      "Traduciendo observación 41/910\n",
      "Traduciendo observación 42/910\n",
      "Traduciendo observación 43/910\n",
      "Traduciendo observación 44/910\n",
      "Traduciendo observación 45/910\n",
      "Traduciendo observación 46/910\n",
      "Traduciendo observación 47/910\n",
      "Traduciendo observación 48/910\n",
      "Traduciendo observación 49/910\n",
      "Traduciendo observación 50/910\n",
      "Traduciendo observación 51/910\n",
      "Traduciendo observación 52/910\n",
      "Traduciendo observación 53/910\n",
      "Traduciendo observación 54/910\n",
      "Traduciendo observación 55/910\n",
      "Traduciendo observación 56/910\n",
      "Traduciendo observación 57/910\n",
      "Traduciendo observación 58/910\n",
      "Traduciendo observación 59/910\n",
      "Traduciendo observación 60/910\n",
      "Traduciendo observación 61/910\n",
      "Traduciendo observación 62/910\n",
      "Traduciendo observación 63/910\n",
      "Traduciendo observación 64/910\n",
      "Traduciendo observación 65/910\n",
      "Traduciendo observación 66/910\n",
      "Traduciendo observación 67/910\n",
      "Traduciendo observación 68/910\n",
      "Traduciendo observación 69/910\n",
      "Traduciendo observación 70/910\n",
      "Traduciendo observación 71/910\n",
      "Traduciendo observación 72/910\n",
      "Traduciendo observación 73/910\n",
      "Traduciendo observación 74/910\n",
      "Traduciendo observación 75/910\n",
      "Traduciendo observación 76/910\n",
      "Traduciendo observación 77/910\n",
      "Traduciendo observación 78/910\n",
      "Traduciendo observación 79/910\n",
      "Traduciendo observación 80/910\n",
      "Traduciendo observación 81/910\n",
      "Traduciendo observación 82/910\n",
      "Traduciendo observación 83/910\n",
      "Traduciendo observación 84/910\n",
      "Traduciendo observación 85/910\n",
      "Traduciendo observación 86/910\n",
      "Traduciendo observación 87/910\n",
      "Traduciendo observación 88/910\n",
      "Traduciendo observación 89/910\n",
      "Traduciendo observación 90/910\n",
      "Traduciendo observación 91/910\n",
      "Traduciendo observación 92/910\n",
      "Traduciendo observación 93/910\n",
      "Traduciendo observación 94/910\n",
      "Traduciendo observación 95/910\n",
      "Traduciendo observación 96/910\n",
      "Traduciendo observación 97/910\n",
      "Traduciendo observación 98/910\n",
      "Traduciendo observación 99/910\n",
      "Traduciendo observación 100/910\n",
      "Traduciendo observación 101/910\n",
      "Traduciendo observación 102/910\n",
      "Traduciendo observación 103/910\n",
      "Traduciendo observación 104/910\n",
      "Traduciendo observación 105/910\n",
      "Traduciendo observación 106/910\n",
      "Traduciendo observación 107/910\n",
      "Traduciendo observación 108/910\n",
      "Traduciendo observación 109/910\n",
      "Traduciendo observación 110/910\n",
      "Traduciendo observación 111/910\n",
      "Traduciendo observación 112/910\n",
      "Traduciendo observación 113/910\n",
      "Traduciendo observación 114/910\n",
      "Traduciendo observación 115/910\n",
      "Traduciendo observación 116/910\n",
      "Traduciendo observación 117/910\n",
      "Traduciendo observación 118/910\n",
      "Traduciendo observación 119/910\n",
      "Traduciendo observación 120/910\n",
      "Traduciendo observación 121/910\n",
      "Traduciendo observación 122/910\n",
      "Traduciendo observación 123/910\n",
      "Traduciendo observación 124/910\n",
      "Traduciendo observación 125/910\n",
      "Traduciendo observación 126/910\n",
      "Traduciendo observación 127/910\n",
      "Traduciendo observación 128/910\n",
      "Traduciendo observación 129/910\n",
      "Traduciendo observación 130/910\n",
      "Traduciendo observación 131/910\n",
      "Traduciendo observación 132/910\n",
      "Traduciendo observación 133/910\n",
      "Traduciendo observación 134/910\n",
      "Traduciendo observación 135/910\n",
      "Traduciendo observación 136/910\n",
      "Traduciendo observación 137/910\n",
      "Traduciendo observación 138/910\n",
      "Traduciendo observación 139/910\n",
      "Traduciendo observación 140/910\n",
      "Traduciendo observación 141/910\n",
      "Traduciendo observación 142/910\n",
      "Traduciendo observación 143/910\n",
      "Traduciendo observación 144/910\n",
      "Traduciendo observación 145/910\n",
      "Traduciendo observación 146/910\n",
      "Traduciendo observación 147/910\n",
      "Traduciendo observación 148/910\n",
      "Traduciendo observación 149/910\n",
      "Traduciendo observación 150/910\n",
      "Traduciendo observación 151/910\n",
      "Traduciendo observación 152/910\n",
      "Traduciendo observación 153/910\n",
      "Traduciendo observación 154/910\n",
      "Traduciendo observación 155/910\n",
      "Traduciendo observación 156/910\n",
      "Traduciendo observación 157/910\n",
      "Traduciendo observación 158/910\n",
      "Traduciendo observación 159/910\n",
      "Traduciendo observación 160/910\n",
      "Traduciendo observación 161/910\n",
      "Traduciendo observación 162/910\n",
      "Traduciendo observación 163/910\n",
      "Traduciendo observación 164/910\n",
      "Traduciendo observación 165/910\n",
      "Traduciendo observación 166/910\n",
      "Traduciendo observación 167/910\n",
      "Traduciendo observación 168/910\n",
      "Traduciendo observación 169/910\n",
      "Traduciendo observación 170/910\n",
      "Traduciendo observación 171/910\n",
      "Traduciendo observación 172/910\n",
      "Traduciendo observación 173/910\n",
      "Traduciendo observación 174/910\n",
      "Traduciendo observación 175/910\n",
      "Traduciendo observación 176/910\n",
      "Traduciendo observación 177/910\n",
      "Traduciendo observación 178/910\n",
      "Traduciendo observación 179/910\n",
      "Traduciendo observación 180/910\n",
      "Traduciendo observación 181/910\n",
      "Traduciendo observación 182/910\n",
      "Traduciendo observación 183/910\n",
      "Traduciendo observación 184/910\n",
      "Traduciendo observación 185/910\n",
      "Traduciendo observación 186/910\n",
      "Traduciendo observación 187/910\n",
      "Traduciendo observación 188/910\n",
      "Traduciendo observación 189/910\n",
      "Traduciendo observación 190/910\n",
      "Traduciendo observación 191/910\n",
      "Traduciendo observación 192/910\n",
      "Traduciendo observación 193/910\n",
      "Traduciendo observación 194/910\n",
      "Traduciendo observación 195/910\n",
      "Traduciendo observación 196/910\n",
      "Traduciendo observación 197/910\n",
      "Traduciendo observación 198/910\n",
      "Traduciendo observación 199/910\n",
      "Traduciendo observación 200/910\n",
      "Traduciendo observación 201/910\n",
      "Traduciendo observación 202/910\n",
      "Traduciendo observación 203/910\n",
      "Traduciendo observación 204/910\n",
      "Traduciendo observación 205/910\n",
      "Traduciendo observación 206/910\n",
      "Traduciendo observación 207/910\n",
      "Traduciendo observación 208/910\n",
      "Traduciendo observación 209/910\n",
      "Traduciendo observación 210/910\n",
      "Traduciendo observación 211/910\n",
      "Traduciendo observación 212/910\n",
      "Traduciendo observación 213/910\n",
      "Traduciendo observación 214/910\n",
      "Traduciendo observación 215/910\n",
      "Traduciendo observación 216/910\n",
      "Traduciendo observación 217/910\n",
      "Traduciendo observación 218/910\n",
      "Traduciendo observación 219/910\n",
      "Traduciendo observación 220/910\n",
      "Traduciendo observación 221/910\n",
      "Traduciendo observación 222/910\n",
      "Traduciendo observación 223/910\n",
      "Traduciendo observación 224/910\n",
      "Traduciendo observación 225/910\n",
      "Traduciendo observación 226/910\n",
      "Traduciendo observación 227/910\n",
      "Traduciendo observación 228/910\n",
      "Traduciendo observación 229/910\n",
      "Traduciendo observación 230/910\n",
      "Traduciendo observación 231/910\n",
      "Traduciendo observación 232/910\n",
      "Traduciendo observación 233/910\n",
      "Traduciendo observación 234/910\n",
      "Traduciendo observación 235/910\n",
      "Traduciendo observación 236/910\n",
      "Traduciendo observación 237/910\n",
      "Traduciendo observación 238/910\n",
      "Traduciendo observación 239/910\n",
      "Traduciendo observación 240/910\n",
      "Traduciendo observación 241/910\n",
      "Traduciendo observación 242/910\n",
      "Traduciendo observación 243/910\n",
      "Traduciendo observación 244/910\n",
      "Traduciendo observación 245/910\n",
      "Traduciendo observación 246/910\n",
      "Traduciendo observación 247/910\n",
      "Traduciendo observación 248/910\n",
      "Traduciendo observación 249/910\n",
      "Traduciendo observación 250/910\n",
      "Traduciendo observación 251/910\n",
      "Traduciendo observación 252/910\n",
      "Traduciendo observación 253/910\n",
      "Traduciendo observación 254/910\n",
      "Traduciendo observación 255/910\n",
      "Traduciendo observación 256/910\n",
      "Traduciendo observación 257/910\n",
      "Traduciendo observación 258/910\n",
      "Traduciendo observación 259/910\n",
      "Traduciendo observación 260/910\n",
      "Traduciendo observación 261/910\n",
      "Traduciendo observación 262/910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduciendo observación 263/910\n",
      "Traduciendo observación 264/910\n",
      "Traduciendo observación 265/910\n",
      "Traduciendo observación 266/910\n",
      "Traduciendo observación 267/910\n",
      "Traduciendo observación 268/910\n",
      "Traduciendo observación 269/910\n",
      "Traduciendo observación 270/910\n",
      "Traduciendo observación 271/910\n",
      "Traduciendo observación 272/910\n",
      "Traduciendo observación 273/910\n",
      "Traduciendo observación 274/910\n",
      "Traduciendo observación 275/910\n",
      "Traduciendo observación 276/910\n",
      "Traduciendo observación 277/910\n",
      "Traduciendo observación 278/910\n",
      "Traduciendo observación 279/910\n",
      "Traduciendo observación 280/910\n",
      "Traduciendo observación 281/910\n",
      "Traduciendo observación 282/910\n",
      "Traduciendo observación 283/910\n",
      "Traduciendo observación 284/910\n",
      "Traduciendo observación 285/910\n",
      "Traduciendo observación 286/910\n",
      "Traduciendo observación 287/910\n",
      "Traduciendo observación 288/910\n",
      "Traduciendo observación 289/910\n",
      "Traduciendo observación 290/910\n",
      "Traduciendo observación 291/910\n",
      "Traduciendo observación 292/910\n",
      "Traduciendo observación 293/910\n",
      "Traduciendo observación 294/910\n",
      "Traduciendo observación 295/910\n",
      "Traduciendo observación 296/910\n",
      "Traduciendo observación 297/910\n",
      "Traduciendo observación 298/910\n",
      "Traduciendo observación 299/910\n",
      "Traduciendo observación 300/910\n",
      "Traduciendo observación 301/910\n",
      "Traduciendo observación 302/910\n",
      "Traduciendo observación 303/910\n",
      "Traduciendo observación 304/910\n",
      "Traduciendo observación 305/910\n",
      "Traduciendo observación 306/910\n",
      "Traduciendo observación 307/910\n",
      "Traduciendo observación 308/910\n",
      "Traduciendo observación 309/910\n",
      "Traduciendo observación 310/910\n",
      "Traduciendo observación 311/910\n",
      "Traduciendo observación 312/910\n",
      "Traduciendo observación 313/910\n",
      "Traduciendo observación 314/910\n",
      "Traduciendo observación 315/910\n",
      "Traduciendo observación 316/910\n",
      "Traduciendo observación 317/910\n",
      "Traduciendo observación 318/910\n",
      "Traduciendo observación 319/910\n",
      "Traduciendo observación 320/910\n",
      "Traduciendo observación 321/910\n",
      "Traduciendo observación 322/910\n",
      "Traduciendo observación 323/910\n",
      "Traduciendo observación 324/910\n",
      "Traduciendo observación 325/910\n",
      "Traduciendo observación 326/910\n",
      "Traduciendo observación 327/910\n",
      "Traduciendo observación 328/910\n",
      "Traduciendo observación 329/910\n",
      "Traduciendo observación 330/910\n",
      "Traduciendo observación 331/910\n",
      "Traduciendo observación 332/910\n",
      "Traduciendo observación 333/910\n",
      "Traduciendo observación 334/910\n",
      "Traduciendo observación 335/910\n",
      "Traduciendo observación 336/910\n",
      "Traduciendo observación 337/910\n",
      "Traduciendo observación 338/910\n",
      "Traduciendo observación 339/910\n",
      "Traduciendo observación 340/910\n",
      "Traduciendo observación 341/910\n",
      "Traduciendo observación 342/910\n",
      "Traduciendo observación 343/910\n",
      "Traduciendo observación 344/910\n",
      "Traduciendo observación 345/910\n",
      "Traduciendo observación 346/910\n",
      "Traduciendo observación 347/910\n",
      "Traduciendo observación 348/910\n",
      "Traduciendo observación 349/910\n",
      "Traduciendo observación 350/910\n",
      "Traduciendo observación 351/910\n",
      "Traduciendo observación 352/910\n",
      "Traduciendo observación 353/910\n",
      "Traduciendo observación 354/910\n",
      "Traduciendo observación 355/910\n",
      "Traduciendo observación 356/910\n",
      "Traduciendo observación 357/910\n",
      "Traduciendo observación 358/910\n",
      "Traduciendo observación 359/910\n",
      "Traduciendo observación 360/910\n",
      "Traduciendo observación 361/910\n",
      "Traduciendo observación 362/910\n",
      "Traduciendo observación 363/910\n",
      "Traduciendo observación 364/910\n",
      "Traduciendo observación 365/910\n",
      "Traduciendo observación 366/910\n",
      "Traduciendo observación 367/910\n",
      "Traduciendo observación 368/910\n",
      "Traduciendo observación 369/910\n",
      "Traduciendo observación 370/910\n",
      "Traduciendo observación 371/910\n",
      "Traduciendo observación 372/910\n",
      "Traduciendo observación 373/910\n",
      "Traduciendo observación 374/910\n",
      "Traduciendo observación 375/910\n",
      "Traduciendo observación 376/910\n",
      "Traduciendo observación 377/910\n",
      "Traduciendo observación 378/910\n",
      "Traduciendo observación 379/910\n",
      "Traduciendo observación 380/910\n",
      "Traduciendo observación 381/910\n",
      "Traduciendo observación 382/910\n",
      "Traduciendo observación 383/910\n",
      "Traduciendo observación 384/910\n",
      "Traduciendo observación 385/910\n",
      "Traduciendo observación 386/910\n",
      "Traduciendo observación 387/910\n",
      "Traduciendo observación 388/910\n",
      "Traduciendo observación 389/910\n",
      "Traduciendo observación 390/910\n",
      "Traduciendo observación 391/910\n",
      "Traduciendo observación 392/910\n",
      "Traduciendo observación 393/910\n",
      "Traduciendo observación 394/910\n",
      "Traduciendo observación 395/910\n",
      "Traduciendo observación 396/910\n",
      "Traduciendo observación 397/910\n",
      "Traduciendo observación 398/910\n",
      "Traduciendo observación 399/910\n",
      "Traduciendo observación 400/910\n",
      "Traduciendo observación 401/910\n",
      "Traduciendo observación 402/910\n",
      "Traduciendo observación 403/910\n",
      "Traduciendo observación 404/910\n",
      "Traduciendo observación 405/910\n",
      "Traduciendo observación 406/910\n",
      "Traduciendo observación 407/910\n",
      "Traduciendo observación 408/910\n",
      "Traduciendo observación 409/910\n",
      "Traduciendo observación 410/910\n",
      "Traduciendo observación 411/910\n",
      "Traduciendo observación 412/910\n",
      "Traduciendo observación 413/910\n",
      "Traduciendo observación 414/910\n",
      "Traduciendo observación 415/910\n",
      "Traduciendo observación 416/910\n",
      "Traduciendo observación 417/910\n",
      "Traduciendo observación 418/910\n",
      "Traduciendo observación 419/910\n",
      "Traduciendo observación 420/910\n",
      "Traduciendo observación 421/910\n",
      "Traduciendo observación 422/910\n",
      "Traduciendo observación 423/910\n",
      "Traduciendo observación 424/910\n",
      "Traduciendo observación 425/910\n",
      "Traduciendo observación 426/910\n",
      "Traduciendo observación 427/910\n",
      "Traduciendo observación 428/910\n",
      "Traduciendo observación 429/910\n",
      "Traduciendo observación 430/910\n",
      "Traduciendo observación 431/910\n",
      "Traduciendo observación 432/910\n",
      "Traduciendo observación 433/910\n",
      "Traduciendo observación 434/910\n",
      "Traduciendo observación 435/910\n",
      "Traduciendo observación 436/910\n",
      "Traduciendo observación 437/910\n",
      "Traduciendo observación 438/910\n",
      "Traduciendo observación 439/910\n",
      "Traduciendo observación 440/910\n",
      "Traduciendo observación 441/910\n",
      "Traduciendo observación 442/910\n",
      "Traduciendo observación 443/910\n",
      "Traduciendo observación 444/910\n",
      "Traduciendo observación 445/910\n",
      "Traduciendo observación 446/910\n",
      "Traduciendo observación 447/910\n",
      "Traduciendo observación 448/910\n",
      "Traduciendo observación 449/910\n",
      "Traduciendo observación 450/910\n",
      "Traduciendo observación 451/910\n",
      "Traduciendo observación 452/910\n",
      "Traduciendo observación 453/910\n",
      "Traduciendo observación 454/910\n",
      "Traduciendo observación 455/910\n",
      "Traduciendo observación 456/910\n",
      "Traduciendo observación 457/910\n",
      "Traduciendo observación 458/910\n",
      "Traduciendo observación 459/910\n",
      "Traduciendo observación 460/910\n",
      "Traduciendo observación 461/910\n",
      "Traduciendo observación 462/910\n",
      "Traduciendo observación 463/910\n",
      "Traduciendo observación 464/910\n",
      "Traduciendo observación 465/910\n",
      "Traduciendo observación 466/910\n",
      "Traduciendo observación 467/910\n",
      "Traduciendo observación 468/910\n",
      "Traduciendo observación 469/910\n",
      "Traduciendo observación 470/910\n",
      "Traduciendo observación 471/910\n",
      "Traduciendo observación 472/910\n",
      "Traduciendo observación 473/910\n",
      "Traduciendo observación 474/910\n",
      "Traduciendo observación 475/910\n",
      "Traduciendo observación 476/910\n",
      "Traduciendo observación 477/910\n",
      "Traduciendo observación 478/910\n",
      "Traduciendo observación 479/910\n",
      "Traduciendo observación 480/910\n",
      "Traduciendo observación 481/910\n",
      "Traduciendo observación 482/910\n",
      "Traduciendo observación 483/910\n",
      "Traduciendo observación 484/910\n",
      "Traduciendo observación 485/910\n",
      "Traduciendo observación 486/910\n",
      "Traduciendo observación 487/910\n",
      "Traduciendo observación 488/910\n",
      "Traduciendo observación 489/910\n",
      "Traduciendo observación 490/910\n",
      "Traduciendo observación 491/910\n",
      "Traduciendo observación 492/910\n",
      "Traduciendo observación 493/910\n",
      "Traduciendo observación 494/910\n",
      "Traduciendo observación 495/910\n",
      "Traduciendo observación 496/910\n",
      "Traduciendo observación 497/910\n",
      "Traduciendo observación 498/910\n",
      "Traduciendo observación 499/910\n",
      "Traduciendo observación 500/910\n",
      "Traduciendo observación 501/910\n",
      "Traduciendo observación 502/910\n",
      "Traduciendo observación 503/910\n",
      "Traduciendo observación 504/910\n",
      "Traduciendo observación 505/910\n",
      "Traduciendo observación 506/910\n",
      "Traduciendo observación 507/910\n",
      "Traduciendo observación 508/910\n",
      "Traduciendo observación 509/910\n",
      "Traduciendo observación 510/910\n",
      "Traduciendo observación 511/910\n",
      "Traduciendo observación 512/910\n",
      "Traduciendo observación 513/910\n",
      "Traduciendo observación 514/910\n",
      "Traduciendo observación 515/910\n",
      "Traduciendo observación 516/910\n",
      "Traduciendo observación 517/910\n",
      "Traduciendo observación 518/910\n",
      "Traduciendo observación 519/910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduciendo observación 520/910\n",
      "Traduciendo observación 521/910\n",
      "Traduciendo observación 522/910\n",
      "Traduciendo observación 523/910\n",
      "Traduciendo observación 524/910\n",
      "Traduciendo observación 525/910\n",
      "Traduciendo observación 526/910\n",
      "Traduciendo observación 527/910\n",
      "Traduciendo observación 528/910\n",
      "Traduciendo observación 529/910\n",
      "Traduciendo observación 530/910\n",
      "Traduciendo observación 531/910\n",
      "Traduciendo observación 532/910\n",
      "Traduciendo observación 533/910\n",
      "Traduciendo observación 534/910\n",
      "Traduciendo observación 535/910\n",
      "Traduciendo observación 536/910\n",
      "Traduciendo observación 537/910\n",
      "Traduciendo observación 538/910\n",
      "Traduciendo observación 539/910\n",
      "Traduciendo observación 540/910\n",
      "Traduciendo observación 541/910\n",
      "Traduciendo observación 542/910\n",
      "Traduciendo observación 543/910\n",
      "Traduciendo observación 544/910\n",
      "Traduciendo observación 545/910\n",
      "Traduciendo observación 546/910\n",
      "Traduciendo observación 547/910\n",
      "Traduciendo observación 548/910\n",
      "Traduciendo observación 549/910\n",
      "Traduciendo observación 550/910\n",
      "Traduciendo observación 551/910\n",
      "Traduciendo observación 552/910\n",
      "Traduciendo observación 553/910\n",
      "Traduciendo observación 554/910\n",
      "Traduciendo observación 555/910\n",
      "Traduciendo observación 556/910\n",
      "Traduciendo observación 557/910\n",
      "Traduciendo observación 558/910\n",
      "Traduciendo observación 559/910\n",
      "Traduciendo observación 560/910\n",
      "Traduciendo observación 561/910\n",
      "Traduciendo observación 562/910\n",
      "Traduciendo observación 563/910\n",
      "Traduciendo observación 564/910\n",
      "Traduciendo observación 565/910\n",
      "Traduciendo observación 566/910\n",
      "Traduciendo observación 567/910\n",
      "Traduciendo observación 568/910\n",
      "Traduciendo observación 569/910\n",
      "Traduciendo observación 570/910\n",
      "Traduciendo observación 571/910\n",
      "Traduciendo observación 572/910\n",
      "Traduciendo observación 573/910\n",
      "Traduciendo observación 574/910\n",
      "Traduciendo observación 575/910\n",
      "Traduciendo observación 576/910\n",
      "Traduciendo observación 577/910\n",
      "Traduciendo observación 578/910\n",
      "Traduciendo observación 579/910\n",
      "Traduciendo observación 580/910\n",
      "Traduciendo observación 581/910\n",
      "Traduciendo observación 582/910\n",
      "Traduciendo observación 583/910\n",
      "Traduciendo observación 584/910\n",
      "Traduciendo observación 585/910\n",
      "Traduciendo observación 586/910\n",
      "Traduciendo observación 587/910\n",
      "Traduciendo observación 588/910\n",
      "Traduciendo observación 589/910\n",
      "Traduciendo observación 590/910\n",
      "Traduciendo observación 591/910\n",
      "Traduciendo observación 592/910\n",
      "Traduciendo observación 593/910\n",
      "Traduciendo observación 594/910\n",
      "Traduciendo observación 595/910\n",
      "Traduciendo observación 596/910\n",
      "Traduciendo observación 597/910\n",
      "Traduciendo observación 598/910\n",
      "Traduciendo observación 599/910\n",
      "Traduciendo observación 600/910\n",
      "Traduciendo observación 601/910\n",
      "Traduciendo observación 602/910\n",
      "Traduciendo observación 603/910\n",
      "Traduciendo observación 604/910\n",
      "Traduciendo observación 605/910\n",
      "Traduciendo observación 606/910\n",
      "Traduciendo observación 607/910\n",
      "Traduciendo observación 608/910\n",
      "Traduciendo observación 609/910\n",
      "Traduciendo observación 610/910\n",
      "Traduciendo observación 611/910\n",
      "Traduciendo observación 612/910\n",
      "Traduciendo observación 613/910\n",
      "Traduciendo observación 614/910\n",
      "Traduciendo observación 615/910\n",
      "Traduciendo observación 616/910\n",
      "Traduciendo observación 617/910\n",
      "Traduciendo observación 618/910\n",
      "Traduciendo observación 619/910\n",
      "Traduciendo observación 620/910\n",
      "Traduciendo observación 621/910\n",
      "Traduciendo observación 622/910\n",
      "Traduciendo observación 623/910\n",
      "Traduciendo observación 624/910\n",
      "Traduciendo observación 625/910\n",
      "Traduciendo observación 626/910\n",
      "Traduciendo observación 627/910\n",
      "Traduciendo observación 628/910\n",
      "Traduciendo observación 629/910\n",
      "Traduciendo observación 630/910\n",
      "Traduciendo observación 631/910\n",
      "Traduciendo observación 632/910\n",
      "Traduciendo observación 633/910\n",
      "Traduciendo observación 634/910\n",
      "Traduciendo observación 635/910\n",
      "Traduciendo observación 636/910\n",
      "Traduciendo observación 637/910\n",
      "Traduciendo observación 638/910\n",
      "Traduciendo observación 639/910\n",
      "Traduciendo observación 640/910\n",
      "Traduciendo observación 641/910\n",
      "Traduciendo observación 642/910\n",
      "Traduciendo observación 643/910\n",
      "Traduciendo observación 644/910\n",
      "Traduciendo observación 645/910\n",
      "Traduciendo observación 646/910\n",
      "Traduciendo observación 647/910\n",
      "Traduciendo observación 648/910\n",
      "Traduciendo observación 649/910\n",
      "Traduciendo observación 650/910\n",
      "Traduciendo observación 651/910\n",
      "Traduciendo observación 652/910\n",
      "Traduciendo observación 653/910\n",
      "Traduciendo observación 654/910\n",
      "Traduciendo observación 655/910\n",
      "Traduciendo observación 656/910\n",
      "Traduciendo observación 657/910\n",
      "Traduciendo observación 658/910\n",
      "Traduciendo observación 659/910\n",
      "Traduciendo observación 660/910\n",
      "Traduciendo observación 661/910\n",
      "Traduciendo observación 662/910\n",
      "Traduciendo observación 663/910\n",
      "Traduciendo observación 664/910\n",
      "Traduciendo observación 665/910\n",
      "Traduciendo observación 666/910\n",
      "Traduciendo observación 667/910\n",
      "Traduciendo observación 668/910\n",
      "Traduciendo observación 669/910\n",
      "Traduciendo observación 670/910\n",
      "Traduciendo observación 671/910\n",
      "Traduciendo observación 672/910\n",
      "Traduciendo observación 673/910\n",
      "Traduciendo observación 674/910\n",
      "Traduciendo observación 675/910\n",
      "Traduciendo observación 676/910\n",
      "Traduciendo observación 677/910\n",
      "Traduciendo observación 678/910\n",
      "Traduciendo observación 679/910\n",
      "Traduciendo observación 680/910\n",
      "Traduciendo observación 681/910\n",
      "Traduciendo observación 682/910\n",
      "Traduciendo observación 683/910\n",
      "Traduciendo observación 684/910\n",
      "Traduciendo observación 685/910\n",
      "Traduciendo observación 686/910\n",
      "Traduciendo observación 687/910\n",
      "Traduciendo observación 688/910\n",
      "Traduciendo observación 689/910\n",
      "Traduciendo observación 690/910\n",
      "Traduciendo observación 691/910\n",
      "Traduciendo observación 692/910\n",
      "Traduciendo observación 693/910\n",
      "Traduciendo observación 694/910\n",
      "Traduciendo observación 695/910\n",
      "Traduciendo observación 696/910\n",
      "Traduciendo observación 697/910\n",
      "Traduciendo observación 698/910\n",
      "Traduciendo observación 699/910\n",
      "Traduciendo observación 700/910\n",
      "Traduciendo observación 701/910\n",
      "Traduciendo observación 702/910\n",
      "Traduciendo observación 703/910\n",
      "Traduciendo observación 704/910\n",
      "Traduciendo observación 705/910\n",
      "Traduciendo observación 706/910\n",
      "Traduciendo observación 707/910\n",
      "Traduciendo observación 708/910\n",
      "Traduciendo observación 709/910\n",
      "Traduciendo observación 710/910\n",
      "Traduciendo observación 711/910\n",
      "Traduciendo observación 712/910\n",
      "Traduciendo observación 713/910\n",
      "Traduciendo observación 714/910\n",
      "Traduciendo observación 715/910\n",
      "Traduciendo observación 716/910\n",
      "Traduciendo observación 717/910\n",
      "Traduciendo observación 718/910\n",
      "Traduciendo observación 719/910\n",
      "Traduciendo observación 720/910\n",
      "Traduciendo observación 721/910\n",
      "Traduciendo observación 722/910\n",
      "Traduciendo observación 723/910\n",
      "Traduciendo observación 724/910\n",
      "Traduciendo observación 725/910\n",
      "Traduciendo observación 726/910\n",
      "Traduciendo observación 727/910\n",
      "Traduciendo observación 728/910\n",
      "Traduciendo observación 729/910\n",
      "Traduciendo observación 730/910\n",
      "Traduciendo observación 731/910\n",
      "Traduciendo observación 732/910\n",
      "Traduciendo observación 733/910\n",
      "Traduciendo observación 734/910\n",
      "Traduciendo observación 735/910\n",
      "Traduciendo observación 736/910\n",
      "Traduciendo observación 737/910\n",
      "Traduciendo observación 738/910\n",
      "Traduciendo observación 739/910\n",
      "Traduciendo observación 740/910\n",
      "Traduciendo observación 741/910\n",
      "Traduciendo observación 742/910\n",
      "Traduciendo observación 743/910\n",
      "Traduciendo observación 744/910\n",
      "Traduciendo observación 745/910\n",
      "Traduciendo observación 746/910\n",
      "Traduciendo observación 747/910\n",
      "Traduciendo observación 748/910\n",
      "Traduciendo observación 749/910\n",
      "Traduciendo observación 750/910\n",
      "Traduciendo observación 751/910\n",
      "Traduciendo observación 752/910\n",
      "Traduciendo observación 753/910\n",
      "Traduciendo observación 754/910\n",
      "Traduciendo observación 755/910\n",
      "Traduciendo observación 756/910\n",
      "Traduciendo observación 757/910\n",
      "Traduciendo observación 758/910\n",
      "Traduciendo observación 759/910\n",
      "Traduciendo observación 760/910\n",
      "Traduciendo observación 761/910\n",
      "Traduciendo observación 762/910\n",
      "Traduciendo observación 763/910\n",
      "Traduciendo observación 764/910\n",
      "Traduciendo observación 765/910\n",
      "Traduciendo observación 766/910\n",
      "Traduciendo observación 767/910\n",
      "Traduciendo observación 768/910\n",
      "Traduciendo observación 769/910\n",
      "Traduciendo observación 770/910\n",
      "Traduciendo observación 771/910\n",
      "Traduciendo observación 772/910\n",
      "Traduciendo observación 773/910\n",
      "Traduciendo observación 774/910\n",
      "Traduciendo observación 775/910\n",
      "Traduciendo observación 776/910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduciendo observación 777/910\n",
      "Traduciendo observación 778/910\n",
      "Traduciendo observación 779/910\n",
      "Traduciendo observación 780/910\n",
      "Traduciendo observación 781/910\n",
      "Traduciendo observación 782/910\n",
      "Traduciendo observación 783/910\n",
      "Traduciendo observación 784/910\n",
      "Traduciendo observación 785/910\n",
      "Traduciendo observación 786/910\n",
      "Traduciendo observación 787/910\n",
      "Traduciendo observación 788/910\n",
      "Traduciendo observación 789/910\n",
      "Traduciendo observación 790/910\n",
      "Traduciendo observación 791/910\n",
      "Traduciendo observación 792/910\n",
      "Traduciendo observación 793/910\n",
      "Traduciendo observación 794/910\n",
      "Traduciendo observación 795/910\n",
      "Traduciendo observación 796/910\n",
      "Traduciendo observación 797/910\n",
      "Traduciendo observación 798/910\n",
      "Traduciendo observación 799/910\n",
      "Traduciendo observación 800/910\n",
      "Traduciendo observación 801/910\n",
      "Traduciendo observación 802/910\n",
      "Traduciendo observación 803/910\n",
      "Traduciendo observación 804/910\n",
      "Traduciendo observación 805/910\n",
      "Traduciendo observación 806/910\n",
      "Traduciendo observación 807/910\n",
      "Traduciendo observación 808/910\n",
      "Traduciendo observación 809/910\n",
      "Traduciendo observación 810/910\n",
      "Traduciendo observación 811/910\n",
      "Traduciendo observación 812/910\n",
      "Traduciendo observación 813/910\n",
      "Traduciendo observación 814/910\n",
      "Traduciendo observación 815/910\n",
      "Traduciendo observación 816/910\n",
      "Traduciendo observación 817/910\n",
      "Traduciendo observación 818/910\n",
      "Traduciendo observación 819/910\n",
      "Traduciendo observación 820/910\n",
      "Traduciendo observación 821/910\n",
      "Traduciendo observación 822/910\n",
      "Traduciendo observación 823/910\n",
      "Traduciendo observación 824/910\n",
      "Traduciendo observación 825/910\n",
      "Traduciendo observación 826/910\n",
      "Traduciendo observación 827/910\n",
      "Traduciendo observación 828/910\n",
      "Traduciendo observación 829/910\n",
      "Traduciendo observación 830/910\n",
      "Traduciendo observación 831/910\n",
      "Traduciendo observación 832/910\n",
      "Traduciendo observación 833/910\n",
      "Traduciendo observación 834/910\n",
      "Traduciendo observación 835/910\n",
      "Traduciendo observación 836/910\n",
      "Traduciendo observación 837/910\n",
      "Traduciendo observación 838/910\n",
      "Traduciendo observación 839/910\n",
      "Traduciendo observación 840/910\n",
      "Traduciendo observación 841/910\n",
      "Traduciendo observación 842/910\n",
      "Traduciendo observación 843/910\n",
      "Traduciendo observación 844/910\n",
      "Traduciendo observación 845/910\n",
      "Traduciendo observación 846/910\n",
      "Traduciendo observación 847/910\n",
      "Traduciendo observación 848/910\n",
      "Traduciendo observación 849/910\n",
      "Traduciendo observación 850/910\n",
      "Traduciendo observación 851/910\n",
      "Traduciendo observación 852/910\n",
      "Traduciendo observación 853/910\n",
      "Traduciendo observación 854/910\n",
      "Traduciendo observación 855/910\n",
      "Traduciendo observación 856/910\n",
      "Traduciendo observación 857/910\n",
      "Traduciendo observación 858/910\n",
      "Traduciendo observación 859/910\n",
      "Traduciendo observación 860/910\n",
      "Traduciendo observación 861/910\n",
      "Traduciendo observación 862/910\n",
      "Traduciendo observación 863/910\n",
      "Traduciendo observación 864/910\n",
      "Traduciendo observación 865/910\n",
      "Traduciendo observación 866/910\n",
      "Traduciendo observación 867/910\n",
      "Traduciendo observación 868/910\n",
      "Traduciendo observación 869/910\n",
      "Traduciendo observación 870/910\n",
      "Traduciendo observación 871/910\n",
      "Traduciendo observación 872/910\n",
      "Traduciendo observación 873/910\n",
      "Traduciendo observación 874/910\n",
      "Traduciendo observación 875/910\n",
      "Traduciendo observación 876/910\n",
      "Traduciendo observación 877/910\n",
      "Traduciendo observación 878/910\n",
      "Traduciendo observación 879/910\n",
      "Traduciendo observación 880/910\n",
      "Traduciendo observación 881/910\n",
      "Traduciendo observación 882/910\n",
      "Traduciendo observación 883/910\n",
      "Traduciendo observación 884/910\n",
      "Traduciendo observación 885/910\n",
      "Traduciendo observación 886/910\n",
      "Traduciendo observación 887/910\n",
      "Traduciendo observación 888/910\n",
      "Traduciendo observación 889/910\n",
      "Traduciendo observación 890/910\n",
      "Traduciendo observación 891/910\n",
      "Traduciendo observación 892/910\n",
      "Traduciendo observación 893/910\n",
      "Traduciendo observación 894/910\n",
      "Traduciendo observación 895/910\n",
      "Traduciendo observación 896/910\n",
      "Traduciendo observación 897/910\n",
      "Traduciendo observación 898/910\n",
      "Traduciendo observación 899/910\n",
      "Traduciendo observación 900/910\n",
      "Traduciendo observación 901/910\n",
      "Traduciendo observación 902/910\n",
      "Traduciendo observación 903/910\n",
      "Traduciendo observación 904/910\n",
      "Traduciendo observación 905/910\n",
      "Traduciendo observación 906/910\n",
      "Traduciendo observación 907/910\n",
      "Traduciendo observación 908/910\n",
      "Traduciendo observación 909/910\n",
      "Traduciendo observación 910/910\n",
      "Traducción completada.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Función para traducir un texto de castellano a inglés\n",
    "def translate_text(text):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest='en')\n",
    "    return translation.text\n",
    "\n",
    "# Aplicar la función a la columna 'frase' del DataFrame\n",
    "for i, text in enumerate(data['frase']):\n",
    "    translated_text = translate_text(text)\n",
    "    data.loc[i, 'frase_traducida'] = translated_text\n",
    "    print(f\"Traduciendo observación {i+1}/{len(data)}\")\n",
    "\n",
    "print(\"Traducción completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e0883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduciendo observación 1/104\n",
      "Traduciendo observación 2/104\n",
      "Traduciendo observación 3/104\n",
      "Traduciendo observación 4/104\n",
      "Traduciendo observación 5/104\n",
      "Traduciendo observación 6/104\n",
      "Traduciendo observación 7/104\n",
      "Traduciendo observación 8/104\n",
      "Traduciendo observación 9/104\n",
      "Traduciendo observación 10/104\n",
      "Traduciendo observación 11/104\n",
      "Traduciendo observación 12/104\n",
      "Traduciendo observación 13/104\n",
      "Traduciendo observación 14/104\n",
      "Traduciendo observación 15/104\n",
      "Traduciendo observación 16/104\n",
      "Traduciendo observación 17/104\n",
      "Traduciendo observación 18/104\n",
      "Traduciendo observación 19/104\n",
      "Traduciendo observación 20/104\n",
      "Traduciendo observación 21/104\n",
      "Traduciendo observación 22/104\n",
      "Traduciendo observación 23/104\n",
      "Traduciendo observación 24/104\n",
      "Traduciendo observación 25/104\n",
      "Traduciendo observación 26/104\n",
      "Traduciendo observación 27/104\n",
      "Traduciendo observación 28/104\n",
      "Traduciendo observación 29/104\n",
      "Traduciendo observación 30/104\n",
      "Traduciendo observación 31/104\n",
      "Traduciendo observación 32/104\n",
      "Traduciendo observación 33/104\n",
      "Traduciendo observación 34/104\n",
      "Traduciendo observación 35/104\n",
      "Traduciendo observación 36/104\n",
      "Traduciendo observación 37/104\n",
      "Traduciendo observación 38/104\n",
      "Traduciendo observación 39/104\n",
      "Traduciendo observación 40/104\n",
      "Traduciendo observación 41/104\n",
      "Traduciendo observación 42/104\n",
      "Traduciendo observación 43/104\n",
      "Traduciendo observación 44/104\n",
      "Traduciendo observación 45/104\n",
      "Traduciendo observación 46/104\n",
      "Traduciendo observación 47/104\n",
      "Traduciendo observación 48/104\n",
      "Traduciendo observación 49/104\n",
      "Traduciendo observación 50/104\n",
      "Traduciendo observación 51/104\n",
      "Traduciendo observación 52/104\n",
      "Traduciendo observación 53/104\n",
      "Traduciendo observación 54/104\n",
      "Traduciendo observación 55/104\n",
      "Traduciendo observación 56/104\n",
      "Traduciendo observación 57/104\n",
      "Traduciendo observación 58/104\n",
      "Traduciendo observación 59/104\n",
      "Traduciendo observación 60/104\n",
      "Traduciendo observación 61/104\n",
      "Traduciendo observación 62/104\n",
      "Traduciendo observación 63/104\n",
      "Traduciendo observación 64/104\n",
      "Traduciendo observación 65/104\n",
      "Traduciendo observación 66/104\n",
      "Traduciendo observación 67/104\n",
      "Traduciendo observación 68/104\n",
      "Traduciendo observación 69/104\n",
      "Traduciendo observación 70/104\n",
      "Traduciendo observación 71/104\n",
      "Traduciendo observación 72/104\n",
      "Traduciendo observación 73/104\n",
      "Traduciendo observación 74/104\n",
      "Traduciendo observación 75/104\n",
      "Traduciendo observación 76/104\n",
      "Traduciendo observación 77/104\n",
      "Traduciendo observación 78/104\n",
      "Traduciendo observación 79/104\n",
      "Traduciendo observación 80/104\n",
      "Traduciendo observación 81/104\n",
      "Traduciendo observación 82/104\n",
      "Traduciendo observación 83/104\n",
      "Traduciendo observación 84/104\n",
      "Traduciendo observación 85/104\n",
      "Traduciendo observación 86/104\n",
      "Traduciendo observación 87/104\n",
      "Traduciendo observación 88/104\n",
      "Traduciendo observación 89/104\n",
      "Traduciendo observación 90/104\n",
      "Traduciendo observación 91/104\n",
      "Traduciendo observación 92/104\n",
      "Traduciendo observación 93/104\n",
      "Traduciendo observación 94/104\n",
      "Traduciendo observación 95/104\n",
      "Traduciendo observación 96/104\n",
      "Traduciendo observación 97/104\n",
      "Traduciendo observación 98/104\n",
      "Traduciendo observación 99/104\n",
      "Traduciendo observación 100/104\n",
      "Traduciendo observación 101/104\n",
      "Traduciendo observación 102/104\n",
      "Traduciendo observación 103/104\n",
      "Traduciendo observación 104/104\n",
      "Traducción completada.\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Función para traducir un texto de castellano a inglés\n",
    "def translate_text(text):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, dest='en')\n",
    "    return translation.text\n",
    "\n",
    "# Aplicar la función a la columna 'frase' del DataFrame\n",
    "for i, text in enumerate(unseen['frase']):\n",
    "    translated_text = translate_text(text)\n",
    "    unseen.loc[i, 'frase_traducida'] = translated_text\n",
    "    print(f\"Traduciendo observación {i+1}/{len(unseen)}\")\n",
    "\n",
    "print(\"Traducción completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b062a3",
   "metadata": {},
   "source": [
    "#### (Aesthetic purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3c785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap strings when printing\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  \n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2c260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un 63.62637362637362% de observaciones positivas en el dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There is a {}% of positive observations in the dataset\".format((sum(data.contiene_indicador)/len(data.contiene_indicador))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814ad87",
   "metadata": {},
   "source": [
    "#### Keep only the desired varaiables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf49628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data[[\"frase_traducida\", \"contiene_indicador\"]]\n",
    "unseen = unseen[[\"frase_traducida\", \"contiene_indicador\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd452e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase_traducida</th>\n",
       "      <th>contiene_indicador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have always been interested how the brain wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I became a professor of clinical neurophysiolo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then, after suffering a cycling accident at ag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was operated by the subdural bruises that I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After studying epilepsy for decades, I found i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     frase_traducida  contiene_indicador\n",
       "0  I have always been interested how the brain wo...                   0\n",
       "1  I became a professor of clinical neurophysiolo...                   0\n",
       "2  Then, after suffering a cycling accident at ag...                   0\n",
       "3  I was operated by the subdural bruises that I ...                   0\n",
       "4  After studying epilepsy for decades, I found i...                   1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f7a6c7",
   "metadata": {},
   "source": [
    "#### Start the SaprNLP session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d35a9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-727b18e0-1c9a-434e-ac96-cbaa5c31247a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.3.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.16.0 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.16 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.42.3 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.42.3 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.42.3 in central\n",
      "\tfound com.google.api-client#google-api-client;2.1.1 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.42.3 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.9.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.9.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.42.3 in central\n",
      "\tfound com.google.api#gax-httpjson;0.105.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.9.0 in central\n",
      "\tfound io.grpc#grpc-core;1.51.0 in central\n",
      "\tfound com.google.api#gax;2.20.1 in central\n",
      "\tfound com.google.api#gax-grpc;2.20.1 in central\n",
      "\tfound io.grpc#grpc-alts;1.51.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.51.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.51.0 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.13.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.13.0 in central\n",
      "\tfound com.google.api#api-common;2.2.2 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound io.grpc#grpc-context;1.51.0 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.6.22 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.10 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.10 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.11.0 in central\n",
      "\tfound org.threeten#threetenbp;1.6.4 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.16.0-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.1 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.51.0 in central\n",
      "\tfound io.grpc#grpc-auth;1.51.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.51.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.28.0 in central\n",
      "\tfound com.google.api.grpc#grpc-google-iam-v1;1.6.22 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.51.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.51.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.51.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.51.0 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.51.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/4.3.2/spark-nlp_2.12-4.3.2.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;4.3.2!spark-nlp_2.12.jar (944ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (15ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (345ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (632ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (20ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-storage/2.16.0/google-cloud-storage-2.16.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-storage;2.16.0!google-cloud-storage.jar (54ms)\n",
      "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.4/tensorflow-cpu_2.12-0.4.4.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4!tensorflow-cpu_2.12.jar (771ms)\n",
      "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
      "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (89ms)\n",
      "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
      "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (25ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#guava;31.1-jre!guava.jar(bundle) (24ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#failureaccess;1.0.1!failureaccess.jar(bundle) (20ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar ...\n",
      "\t[SUCCESSFUL ] com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava!listenablefuture.jar (10ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/errorprone/error_prone_annotations/2.16/error_prone_annotations-2.16.jar ...\n",
      "\t[SUCCESSFUL ] com.google.errorprone#error_prone_annotations;2.16!error_prone_annotations.jar (7ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.j2objc#j2objc-annotations;1.3!j2objc-annotations.jar (20ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client/1.42.3/google-http-client-1.42.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client;1.42.3!google-http-client.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-contrib-http-util/0.31.1/opencensus-contrib-http-util-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-contrib-http-util;0.31.1!opencensus-contrib-http-util.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-jackson2/1.42.3/google-http-client-jackson2-1.42.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-jackson2;1.42.3!google-http-client-jackson2.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-gson/1.42.3/google-http-client-gson-1.42.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-gson;1.42.3!google-http-client-gson.jar (19ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api-client/google-api-client/2.1.1/google-api-client-2.1.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api-client#google-api-client;2.1.1!google-api-client.jar (13ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.15/commons-codec-1.15.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.15!commons-codec.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/oauth-client/google-oauth-client/1.34.1/google-oauth-client-1.34.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.oauth-client#google-oauth-client;1.34.1!google-oauth-client.jar (13ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-apache-v2/1.42.3/google-http-client-apache-v2-1.42.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-apache-v2;1.42.3!google-http-client-apache-v2.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/apis/google-api-services-storage/v1-rev20220705-2.0.0/google-api-services-storage-v1-rev20220705-2.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0!google-api-services-storage.jar (10ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.10/gson-2.10.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.10!gson.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core/2.9.0/google-cloud-core-2.9.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core;2.9.0!google-cloud-core.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auto/value/auto-value-annotations/1.10.1/auto-value-annotations-1.10.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auto.value#auto-value-annotations;1.10.1!auto-value-annotations.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-http/2.9.0/google-cloud-core-http-2.9.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-http;2.9.0!google-cloud-core-http.jar (7ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/http-client/google-http-client-appengine/1.42.3/google-http-client-appengine-1.42.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.http-client#google-http-client-appengine;1.42.3!google-http-client-appengine.jar (10ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-httpjson/0.105.1/gax-httpjson-0.105.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-httpjson;0.105.1!gax-httpjson.jar (22ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/cloud/google-cloud-core-grpc/2.9.0/google-cloud-core-grpc-2.9.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.cloud#google-cloud-core-grpc;2.9.0!google-cloud-core-grpc.jar (5ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-core/1.51.0/grpc-core-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-core;1.51.0!grpc-core.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax/2.20.1/gax-2.20.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax;2.20.1!gax.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/gax-grpc/2.20.1/gax-grpc-2.20.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#gax-grpc;2.20.1!gax-grpc.jar (10ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-alts/1.51.0/grpc-alts-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-alts;1.51.0!grpc-alts.jar (24ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-grpclb/1.51.0/grpc-grpclb-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-grpclb;1.51.0!grpc-grpclb.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/org/conscrypt/conscrypt-openjdk-uber/2.5.2/conscrypt-openjdk-uber-2.5.2.jar ...\n",
      "\t[SUCCESSFUL ] org.conscrypt#conscrypt-openjdk-uber;2.5.2!conscrypt-openjdk-uber.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf/1.51.0/grpc-protobuf-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf;1.51.0!grpc-protobuf.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-credentials/1.13.0/google-auth-library-credentials-1.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-credentials;1.13.0!google-auth-library-credentials.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/auth/google-auth-library-oauth2-http/1.13.0/google-auth-library-oauth2-http-1.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.auth#google-auth-library-oauth2-http;1.13.0!google-auth-library-oauth2-http.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/api-common/2.2.2/api-common-2.2.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api#api-common;2.2.2!api-common.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar ...\n",
      "\t[SUCCESSFUL ] javax.annotation#javax.annotation-api;1.3.2!javax.annotation-api.jar (6ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-api/0.31.1/opencensus-api-0.31.1.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-api;0.31.1!opencensus-api.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-context/1.51.0/grpc-context-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-context;1.51.0!grpc-context.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-iam-v1/1.6.22/proto-google-iam-v1-1.6.22.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-iam-v1;1.6.22!proto-google-iam-v1.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.21.10/protobuf-java-3.21.10.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.21.10!protobuf-java.jar(bundle) (28ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.21.10/protobuf-java-util-3.21.10.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.21.10!protobuf-java-util.jar(bundle) (7ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-common-protos/2.11.0/proto-google-common-protos-2.11.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-common-protos;2.11.0!proto-google-common-protos.jar (17ms)\n",
      "downloading https://repo1.maven.org/maven2/org/threeten/threetenbp/1.6.4/threetenbp-1.6.4.jar ...\n",
      "\t[SUCCESSFUL ] org.threeten#threetenbp;1.6.4!threetenbp.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/proto-google-cloud-storage-v2/2.16.0-alpha/proto-google-cloud-storage-v2-2.16.0-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#proto-google-cloud-storage-v2;2.16.0-alpha!proto-google-cloud-storage-v2.jar (12ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/grpc-google-cloud-storage-v2/2.16.0-alpha/grpc-google-cloud-storage-v2-2.16.0-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#grpc-google-cloud-storage-v2;2.16.0-alpha!grpc-google-cloud-storage-v2.jar (15ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/gapic-google-cloud-storage-v2/2.16.0-alpha/gapic-google-cloud-storage-v2-2.16.0-alpha.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#gapic-google-cloud-storage-v2;2.16.0-alpha!gapic-google-cloud-storage-v2.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.14.1/jackson-core-2.14.1.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.14.1!jackson-core.jar(bundle) (10ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (7ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-api/1.51.0/grpc-api-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-api;1.51.0!grpc-api.jar (10ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-auth/1.51.0/grpc-auth-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-auth;1.51.0!grpc-auth.jar (14ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-stub/1.51.0/grpc-stub-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-stub;1.51.0!grpc-stub.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.28.0/checker-qual-3.28.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.28.0!checker-qual.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/api/grpc/grpc-google-iam-v1/1.6.22/grpc-google-iam-v1-1.6.22.jar ...\n",
      "\t[SUCCESSFUL ] com.google.api.grpc#grpc-google-iam-v1;1.6.22!grpc-google-iam-v1.jar (9ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-protobuf-lite/1.51.0/grpc-protobuf-lite-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-protobuf-lite;1.51.0!grpc-protobuf-lite.jar (6ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar ...\n",
      "\t[SUCCESSFUL ] com.google.android#annotations;4.1.1.4!annotations.jar (33ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/mojo/animal-sniffer-annotations/1.22/animal-sniffer-annotations-1.22.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.mojo#animal-sniffer-annotations;1.22!animal-sniffer-annotations.jar (10ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-netty-shaded/1.51.0/grpc-netty-shaded-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-netty-shaded;1.51.0!grpc-netty-shaded.jar (53ms)\n",
      "downloading https://repo1.maven.org/maven2/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar ...\n",
      "\t[SUCCESSFUL ] io.perfmark#perfmark-api;0.26.0!perfmark-api.jar (4ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-googleapis/1.51.0/grpc-googleapis-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-googleapis;1.51.0!grpc-googleapis.jar (8ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-xds/1.51.0/grpc-xds-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-xds;1.51.0!grpc-xds.jar (56ms)\n",
      "downloading https://repo1.maven.org/maven2/io/opencensus/opencensus-proto/0.2.0/opencensus-proto-0.2.0.jar ...\n",
      "\t[SUCCESSFUL ] io.opencensus#opencensus-proto;0.2.0!opencensus-proto.jar (11ms)\n",
      "downloading https://repo1.maven.org/maven2/io/grpc/grpc-services/1.51.0/grpc-services-1.51.0.jar ...\n",
      "\t[SUCCESSFUL ] io.grpc#grpc-services;1.51.0!grpc-services.jar (16ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/re2j/re2j/1.6/re2j-1.6.jar ...\n",
      "\t[SUCCESSFUL ] com.google.re2j#re2j;1.6!re2j.jar (7ms)\n",
      "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
      "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (9ms)\n",
      ":: resolution report :: resolve 14441ms :: artifacts dl 3860ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.1 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.2.2 from central in [default]\n",
      "\tcom.google.api#gax;2.20.1 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.20.1 from central in [default]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tcom.google.api#gax-httpjson;0.105.1 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.1.1 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-iam-v1;1.6.22 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.16.0-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.11.0 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.6.22 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.13.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.13.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.9.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.16.0 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.16 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.42.3 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.42.3 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.10 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.10 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.3.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.51.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.51.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.28.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.10] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.10] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   73  |   73  |   73  |   3   ||   70  |   70  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-727b18e0-1c9a-434e-ac96-cbaa5c31247a\n",
      "\tconfs: [default]\n",
      "\t70 artifacts copied, 0 already retrieved (614376kB/548ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/08 09:18:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Start the Spark NLP session\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ae3d5",
   "metadata": {},
   "source": [
    "#### Transform the pandas dataframes into spark dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9adbddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 0) / 1]\r",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     frase_traducida|contiene_indicador|\n",
      "+--------------------+------------------+\n",
      "|I have always bee...|                 0|\n",
      "|I became a profes...|                 0|\n",
      "|Then, after suffe...|                 0|\n",
      "|I was operated by...|                 0|\n",
      "|After studying ep...|                 1|\n",
      "|that now I was a ...|                 1|\n",
      "|I have evolved to...|                 1|\n",
      "|I have evolved to...|                 1|\n",
      "|I have evolved to...|                 1|\n",
      "|of epilepsy to pe...|                 0|\n",
      "|I share my experi...|                 1|\n",
      "|, And promote the...|                 1|\n",
      "|I self -explore i...|                 1|\n",
      "|For me my mind wa...|                 1|\n",
      "|For me my mind wa...|                 1|\n",
      "|that is, a separa...|                 1|\n",
      "|that is to say th...|                 1|\n",
      "|And starting to o...|                 1|\n",
      "|This help is not ...|                 1|\n",
      "|And you know that...|                 1|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Manually define schema\n",
    "schema = StructType([\n",
    "    StructField(\"frase_traducida\", StringType(), nullable=True),\n",
    "    StructField(\"contiene_indicador\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "rdd_data = spark.sparkContext.parallelize(data.values.tolist())\n",
    "\n",
    "# Create the Spark DataFrame from the RDD and the schema\n",
    "frases = spark.createDataFrame(rdd_data, schema)\n",
    "\n",
    "# Verify it's been created correctly\n",
    "frases.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8d5c227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     frase_traducida|contiene_indicador|\n",
      "+--------------------+------------------+\n",
      "|It is not somethi...|                 1|\n",
      "|thus to support o...|                 1|\n",
      "|        And not fall|                 1|\n",
      "|Because cancer to...|                 1|\n",
      "|go ahead and have...|                 1|\n",
      "|Because here I ha...|                 1|\n",
      "|That is why I nev...|                 1|\n",
      "|And the next day ...|                 1|\n",
      "|“Hello, my name i...|                 0|\n",
      "|10 years ago I wa...|                 1|\n",
      "|Due to the tumor ...|                 0|\n",
      "|I already recover...|                 1|\n",
      "|In December last ...|                 1|\n",
      "|, but this time t...|                 1|\n",
      "|I am currently in...|                 0|\n",
      "|The recovery is s...|                 1|\n",
      "|, and surely with...|                 1|\n",
      "|, and surely with...|                 1|\n",
      "|I want to thank n...|                 1|\n",
      "|, and to all the ...|                 1|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manually define schema\n",
    "schema = StructType([\n",
    "    StructField(\"frase_traducida\", StringType(), nullable=True),\n",
    "    StructField(\"contiene_indicador\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "rdd_data = spark.sparkContext.parallelize(unseen.values.tolist())\n",
    "\n",
    "# Create the Spark DataFrame from the RDD and the schema\n",
    "unseen = spark.createDataFrame(rdd_data, schema)\n",
    "\n",
    "# Verify it's been created correctly\n",
    "unseen.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45a6bb",
   "metadata": {},
   "source": [
    "#### Dividing input data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b8c93b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = frases.randomSplit([0.8, 0.2], seed = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268bf9b",
   "metadata": {},
   "source": [
    "## Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d214cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "23/07/02 21:33:19 ERROR OWLQN: Failure! Resetting history: breeze.optimize.NaNHistory: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes_36f489cb7e77</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'features', 'labelCol': 'label...</td>\n",
       "      <td>0.933823</td>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.932176</td>\n",
       "      <td>0.620042</td>\n",
       "      <td>0.636872</td>\n",
       "      <td>0.621070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes_9933c180f4cf</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'features', 'labelCol': 'label...</td>\n",
       "      <td>0.919216</td>\n",
       "      <td>0.916553</td>\n",
       "      <td>0.914897</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.622569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes_b2ac2b53e361</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'features', 'labelCol': 'label...</td>\n",
       "      <td>0.910217</td>\n",
       "      <td>0.904241</td>\n",
       "      <td>0.901403</td>\n",
       "      <td>0.635364</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.620947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression_ea7859ae3a78</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'featuresCol': 'features', 'labelCol': 'label...</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.993146</td>\n",
       "      <td>0.654482</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.656334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_bf6c0993cb58</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'featuresCol': 'features', 'labelCol': 'label...</td>\n",
       "      <td>0.978837</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.977954</td>\n",
       "      <td>0.627995</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.616474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model          Model_name   \n",
       "0          NaiveBayes_36f489cb7e77          NaiveBayes  \\\n",
       "1          NaiveBayes_9933c180f4cf          NaiveBayes   \n",
       "2          NaiveBayes_b2ac2b53e361          NaiveBayes   \n",
       "3  LogisticRegression_ea7859ae3a78  LogisticRegression   \n",
       "4  LogisticRegression_bf6c0993cb58  LogisticRegression   \n",
       "\n",
       "                                              params  train_acc  train_rec   \n",
       "0  {'featuresCol': 'features', 'labelCol': 'label...   0.933823   0.932969  \\\n",
       "1  {'featuresCol': 'features', 'labelCol': 'label...   0.919216   0.916553   \n",
       "2  {'featuresCol': 'features', 'labelCol': 'label...   0.910217   0.904241   \n",
       "3  {'featuresCol': 'features', 'labelCol': 'label...   0.993233   0.993160   \n",
       "4  {'featuresCol': 'features', 'labelCol': 'label...   0.978837   0.978112   \n",
       "\n",
       "   train_f1  test_acc  test_rec   test_f1  \n",
       "0  0.932176  0.620042  0.636872  0.621070  \n",
       "1  0.914897  0.629000  0.648045  0.622569  \n",
       "2  0.901403  0.635364  0.653631  0.620947  \n",
       "3  0.993146  0.654482  0.659218  0.656334  \n",
       "4  0.977954  0.627995  0.648045  0.616474  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we define the modules that will compose the NLP pipeline, \n",
    "# next we create a function to train different models with different\n",
    "# hyperparameter combinations while saving the results in a dataframe\n",
    "\n",
    "# Define the assembler\n",
    "assembler = DocumentAssembler()\\\n",
    "  .setInputCol('frase_traducida')\\\n",
    "  .setOutputCol('document')\n",
    "docs = assembler.transform(frases)\n",
    "docs.limit(5).toPandas()\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols(['document'])\\\n",
    "  .setOutputCol('tokens')\n",
    "\n",
    "# Define the lemmetizer\n",
    "lemmatizer = LemmatizerModel.pretrained()\\\n",
    "  .setInputCols(['tokens'])\\\n",
    "  .setOutputCol('lemma')\n",
    "\n",
    "# Define the normalizer\n",
    "normalizer = Normalizer()\\\n",
    "  .setInputCols(['lemma'])\\\n",
    "  .setOutputCol('normalized')\\\n",
    "  .setLowercase(True)\n",
    "\n",
    "# Define the finisher\n",
    "finisher = Finisher()\\\n",
    "  .setInputCols(['normalized'])\\\n",
    "  .setOutputCols(['normalized'])\\\n",
    "  .setOutputAsArray(True)\n",
    "\n",
    "# Define the stop words\n",
    "stopwords = set(StopWordsRemover.loadDefaultStopWords('english'))\n",
    "\n",
    "# Define the stopword remover\n",
    "sw_remover = StopWordsRemover()\\\n",
    "  .setInputCol('normalized')\\\n",
    "  .setOutputCol('filtered')\\\n",
    "  .setStopWords(list(stopwords))\n",
    "\n",
    "count_vectorizer = CountVectorizer(\n",
    "  inputCol='filtered',\n",
    "  outputCol='features'\n",
    ")\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "text_processing_pipeline = Pipeline(\n",
    "  stages = [\n",
    "    assembler,\n",
    "    tokenizer,\n",
    "    lemmatizer,\n",
    "    normalizer,\n",
    "    finisher,\n",
    "    sw_remover,\n",
    "    count_vectorizer\n",
    "   ])\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "# Define a function to convert predicted indices to labels\n",
    "prediction_deindexer = IndexToString(\n",
    "  inputCol = 'prediction', \n",
    "  outputCol = 'pred_label', \n",
    "  labels = label_indexer.labels)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "def fit_model(model):\n",
    "    # Construct the overall pipeline\n",
    "    pipeline = Pipeline(\n",
    "        stages=[\n",
    "            text_processing_pipeline,\n",
    "            label_indexer,\n",
    "            model,\n",
    "            prediction_deindexer\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predicted = model.transform(train)\n",
    "    test_predicted = model.transform(test)\n",
    "\n",
    "    # Initialize the evaluators\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the train set\n",
    "    train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "    train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "    train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the test set\n",
    "    test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "    test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "    test_f1 = evaluator_f1.evaluate(test_predicted)\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    result = {\n",
    "        'Train Precision': train_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Train F1 Score': train_f1,\n",
    "        'Test Precision': test_precision,\n",
    "        'Test Recall': test_recall,\n",
    "        'Test F1 Score': test_f1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(result, index=[0])\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define the common options for featuresCol and labelCol\n",
    "common_options = {\n",
    "    'featuresCol': 'features',\n",
    "    'labelCol': 'label'\n",
    "}\n",
    "\n",
    "# Define the hyperparameter options for each model\n",
    "hyperparameter_options = {\n",
    "    'NaiveBayes': {\n",
    "        'smoothing': [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'maxIter': [50, 100, 200],\n",
    "        'regParam': [0.0, 0.1, 0.2]\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'maxIter': [50, 100, 200],\n",
    "        'regParam': [0.0, 0.1, 0.2]\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'numTrees': [10, 20, 30],\n",
    "        'maxDepth': [3, 5, 7]\n",
    "    },\n",
    "    'GBTClassifier': {\n",
    "        'maxIter': [10, 20, 30],\n",
    "        'maxDepth': [3, 5, 7],\n",
    "        'stepSize': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters for each model\n",
    "model_list = []\n",
    "for model_name, options in hyperparameter_options.items():\n",
    "    for params in itertools.product(*options.values()):\n",
    "        model_params = dict(list(common_options.items()) + list(zip(options.keys(), params)))\n",
    "        model = eval(f\"{model_name}(**model_params)\")\n",
    "        model_list.append(model)\n",
    "\n",
    "# Create a list of dictionaries with model names and parameters\n",
    "results = []\n",
    "for model_name, options in hyperparameter_options.items():\n",
    "    for params in itertools.product(*options.values()):\n",
    "        model_params = dict(list(common_options.items()) + list(zip(options.keys(), params)))\n",
    "        result = {\n",
    "            'Model_name': model_name,\n",
    "            'Parameters': model_params\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create the results DataFrame\n",
    "bow_results = pd.concat([pd.DataFrame(model_list, columns=[\"Model\"]), pd.DataFrame(results)], axis=1)\n",
    "\n",
    "bow_results.head()\n",
    "\n",
    "# Merge with the combinatios to form the desired output dataframe\n",
    "metrics = pd.DataFrame()\n",
    "for model in bow_results.Model:\n",
    "    metrics = pd.concat([metrics, fit_model(model)], axis = 0)\n",
    "    \n",
    "bow_results = pd.concat([bow_results, metrics.reset_index(drop = True)], axis = 1, ignore_index=True)\n",
    "new_column_names = {0: 'Model', 1: 'Model_name', 2: 'params', 3:'train_acc', 4:'train_rec', 5:'train_f1', 6:'test_acc', 7:'test_rec', 8:'test_f1'}\n",
    "bow_results.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "bow_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad2412af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '94XGM6J8C31PE61P',\n",
       "  'HostId': 'KwUsVPY68J8I+14STVMrJ2NL7uv/1xhj1O1mfBAstGFAqVMk8hTAZ4K3EyxTzzRc88eFF7Ijdg4=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'KwUsVPY68J8I+14STVMrJ2NL7uv/1xhj1O1mfBAstGFAqVMk8hTAZ4K3EyxTzzRc88eFF7Ijdg4=',\n",
       "   'x-amz-request-id': '94XGM6J8C31PE61P',\n",
       "   'date': 'Sun, 02 Jul 2023 21:39:46 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"1bdfd64fc6f9b440b9651ebec0a72df8\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"1bdfd64fc6f9b440b9651ebec0a72df8\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV format in memory.\n",
    "csv_buffer = bow_results.to_csv(index=False).encode()\n",
    "\n",
    "# Create an instance of the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Sepcify file name and route in the S3\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'bow_results_S3.csv'\n",
    "\n",
    "# Uppload file to the S3 bucket\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=bucket_name, Key=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71642d4",
   "metadata": {},
   "source": [
    "# TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c460a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.3.0.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/02 21:06:04 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/07/02 21:06:04 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/07/02 21:06:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/07/02 21:06:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2832:>                                                       (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Model_name</th>\n",
       "      <th>params</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayes_26dc767f2ae1</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'tfidf', 'labelCol': 'label', ...</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.616268</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.611937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes_35f4a3499532</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'tfidf', 'labelCol': 'label', ...</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.613756</td>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.611051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayes_b8e962b8748f</td>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>{'featuresCol': 'tfidf', 'labelCol': 'label', ...</td>\n",
       "      <td>0.943870</td>\n",
       "      <td>0.943912</td>\n",
       "      <td>0.943889</td>\n",
       "      <td>0.606983</td>\n",
       "      <td>0.603352</td>\n",
       "      <td>0.605003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression_7136759f226b</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'featuresCol': 'tfidf', 'labelCol': 'label', ...</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.993146</td>\n",
       "      <td>0.654482</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.656334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_c6850738d187</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'featuresCol': 'tfidf', 'labelCol': 'label', ...</td>\n",
       "      <td>0.978837</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.977954</td>\n",
       "      <td>0.627995</td>\n",
       "      <td>0.648045</td>\n",
       "      <td>0.616474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model          Model_name   \n",
       "0          NaiveBayes_26dc767f2ae1          NaiveBayes  \\\n",
       "1          NaiveBayes_35f4a3499532          NaiveBayes   \n",
       "2          NaiveBayes_b8e962b8748f          NaiveBayes   \n",
       "3  LogisticRegression_7136759f226b  LogisticRegression   \n",
       "4  LogisticRegression_c6850738d187  LogisticRegression   \n",
       "\n",
       "                                              params  train_acc  train_rec   \n",
       "0  {'featuresCol': 'tfidf', 'labelCol': 'label', ...   0.942544   0.942544  \\\n",
       "1  {'featuresCol': 'tfidf', 'labelCol': 'label', ...   0.942544   0.942544   \n",
       "2  {'featuresCol': 'tfidf', 'labelCol': 'label', ...   0.943870   0.943912   \n",
       "3  {'featuresCol': 'tfidf', 'labelCol': 'label', ...   0.993233   0.993160   \n",
       "4  {'featuresCol': 'tfidf', 'labelCol': 'label', ...   0.978837   0.978112   \n",
       "\n",
       "   train_f1  test_acc  test_rec   test_f1  \n",
       "0  0.942544  0.616268  0.608939  0.611937  \n",
       "1  0.942544  0.613756  0.608939  0.611051  \n",
       "2  0.943889  0.606983  0.603352  0.605003  \n",
       "3  0.993146  0.654482  0.659218  0.656334  \n",
       "4  0.977954  0.627995  0.648045  0.616474  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we define the modules that will compose the NLP pipeline, \n",
    "# next we create a function to train different models with different\n",
    "# hyperparameter combinations while saving the results in a dataframe\n",
    "\n",
    "# Define the assembler\n",
    "assembler = DocumentAssembler()\\\n",
    "  .setInputCol('frase_traducida')\\\n",
    "  .setOutputCol('document')\n",
    "docs = assembler.transform(frases)\n",
    "docs.limit(5).toPandas()\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols(['document'])\\\n",
    "  .setOutputCol('tokens')\n",
    "\n",
    "# Define the lemmetizer\n",
    "lemmatizer = LemmatizerModel.pretrained()\\\n",
    "  .setInputCols(['tokens'])\\\n",
    "  .setOutputCol('lemma')\n",
    "\n",
    "# Define the normalizer\n",
    "normalizer = Normalizer()\\\n",
    "  .setInputCols(['lemma'])\\\n",
    "  .setOutputCol('normalized')\\\n",
    "  .setLowercase(True)\n",
    "\n",
    "# Define the finisher\n",
    "finisher = Finisher()\\\n",
    "  .setInputCols(['normalized'])\\\n",
    "  .setOutputCols(['normalized'])\\\n",
    "  .setOutputAsArray(True)\n",
    "\n",
    "# Define the stop words\n",
    "stopwords = set(StopWordsRemover.loadDefaultStopWords('english'))\n",
    "\n",
    "# Define the stopword remover\n",
    "sw_remover = StopWordsRemover()\\\n",
    "  .setInputCol('normalized')\\\n",
    "  .setOutputCol('filtered')\\\n",
    "  .setStopWords(list(stopwords))\n",
    "\n",
    "# Define count vectorizer\n",
    "count_vectorizer = CountVectorizer(\n",
    "  inputCol = 'filtered',\n",
    "  outputCol = 'tf'\n",
    "  )\n",
    "\n",
    "# Define TF-IDF\n",
    "tfidf = IDF(\n",
    "  inputCol = 'tf',\n",
    "  outputCol = 'tfidf'\n",
    "  )\n",
    "\n",
    "# Define the pipeline\n",
    "text_processing_pipeline = Pipeline(\n",
    "  stages = [\n",
    "    assembler,\n",
    "    tokenizer,\n",
    "    lemmatizer,\n",
    "    normalizer,\n",
    "    finisher,\n",
    "    sw_remover,\n",
    "    count_vectorizer,\n",
    "    tfidf\n",
    "   ])\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "# Define a function to convert predicted indices to labels\n",
    "prediction_deindexer = IndexToString(\n",
    "  inputCol = 'prediction', \n",
    "  outputCol = 'pred_label', \n",
    "  labels = label_indexer.labels)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "def fit_model(model):\n",
    "    # Construct the overall pipeline\n",
    "    pipeline = Pipeline(\n",
    "        stages=[\n",
    "            text_processing_pipeline,\n",
    "            label_indexer,\n",
    "            model,\n",
    "            prediction_deindexer\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predicted = model.transform(train)\n",
    "    test_predicted = model.transform(test)\n",
    "\n",
    "    # Initialize the evaluators\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the train set\n",
    "    train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "    train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "    train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the test set\n",
    "    test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "    test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "    test_f1 = evaluator_f1.evaluate(test_predicted)\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    result = {\n",
    "        'Train Precision': train_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Train F1 Score': train_f1,\n",
    "        'Test Precision': test_precision,\n",
    "        'Test Recall': test_recall,\n",
    "        'Test F1 Score': test_f1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(result, index=[0])\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Define the common options for featuresCol and labelCol\n",
    "common_options = {\n",
    "    'featuresCol': 'tfidf',\n",
    "    'labelCol': 'label'\n",
    "}\n",
    "\n",
    "# Define the hyperparameter options for each model\n",
    "hyperparameter_options = {\n",
    "    'NaiveBayes': {\n",
    "        'smoothing': [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'maxIter': [50, 100, 200],\n",
    "        'regParam': [0.0, 0.1, 0.2]\n",
    "    },\n",
    "    'LinearSVC': {\n",
    "        'maxIter': [50, 100, 200],\n",
    "        'regParam': [0.0, 0.1, 0.2]\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'numTrees': [10, 20, 30],\n",
    "        'maxDepth': [3, 5, 7]\n",
    "    },\n",
    "    'GBTClassifier': {\n",
    "        'maxIter': [10, 20, 30],\n",
    "        'maxDepth': [3, 5, 7],\n",
    "        'stepSize': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters for each model\n",
    "model_list = []\n",
    "for model_name, options in hyperparameter_options.items():\n",
    "    for params in itertools.product(*options.values()):\n",
    "        model_params = dict(list(common_options.items()) + list(zip(options.keys(), params)))\n",
    "        model = eval(f\"{model_name}(**model_params)\")\n",
    "        model_list.append(model)\n",
    "\n",
    "# Create a list of dictionaries with model names and parameters\n",
    "results = []\n",
    "for model_name, options in hyperparameter_options.items():\n",
    "    for params in itertools.product(*options.values()):\n",
    "        model_params = dict(list(common_options.items()) + list(zip(options.keys(), params)))\n",
    "        result = {\n",
    "            'Model_name': model_name,\n",
    "            'Parameters': model_params\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create the results DataFrame\n",
    "tfidf_results = pd.concat([pd.DataFrame(model_list, columns = [\"Model\"]), pd.DataFrame(results)], axis = 1)\n",
    "\n",
    "tfidf_results.head()\n",
    "\n",
    "# Merge with the combinatios to form the desired output dataframe\n",
    "metrics = pd.DataFrame()\n",
    "for model in tfidf_results.Model:\n",
    "    metrics = pd.concat([metrics, fit_model(model)], axis = 0)\n",
    "    \n",
    "tfidf_results = pd.concat([tfidf_results, metrics.reset_index(drop = True)], axis = 1, ignore_index=True)\n",
    "new_column_names = {0: 'Model', 1: 'Model_name', 2: 'params', 3:'train_acc', 4:'train_rec', 5:'train_f1', 6:'test_acc', 7:'test_rec', 8:'test_f1'}\n",
    "tfidf_results.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "tfidf_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "482cbd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3FEJ8HED3V7TTCMF',\n",
       "  'HostId': '8mbDYaHIiExXEqxCmJEVmD6anUd8pPHvER0irq+fkBOH/XmE50VlkbxzRFHwDdppSaYnSkZpvt4=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '8mbDYaHIiExXEqxCmJEVmD6anUd8pPHvER0irq+fkBOH/XmE50VlkbxzRFHwDdppSaYnSkZpvt4=',\n",
       "   'x-amz-request-id': '3FEJ8HED3V7TTCMF',\n",
       "   'date': 'Sun, 02 Jul 2023 21:19:19 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"9e57c9903a25621a2c8bc7767bbcdb99\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"9e57c9903a25621a2c8bc7767bbcdb99\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV format in memory.\n",
    "csv_buffer = tfidf_results.to_csv(index=False).encode()\n",
    "\n",
    "# Create an instance of the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Sepcify file name and route in the S3\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'tfidf_results_S3.csv'\n",
    "\n",
    "# Uppload file to the S3 bucket\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=bucket_name, Key=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f8f44a",
   "metadata": {},
   "source": [
    "# DEEP LEARNING APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d6c2e",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36507a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define the modules that will compose the NLP pipeline, \n",
    "# next we create a function to train different models with different\n",
    "# hyperparameter combinations while saving the results in a dataframe\n",
    "\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "# Define the assembler\n",
    "document_assembler = DocumentAssembler().setInputCol('frase_traducida').setOutputCol('document')\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n",
    "\n",
    "# Define the stopword remover\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    ".setInputCols(\"token\")\\\n",
    ".setOutputCol(\"cleanedToken\")\n",
    "\n",
    "# Create the sentence embeddings feature extractor\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "  .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"sentence_embeddings\") \\\n",
    "  .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "def fit_model(epochs):\n",
    "    \n",
    "    # Create the feature extractor using GloVe word embeddings\n",
    "    embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\") \\\n",
    "      .setInputCols([\"document\", \"cleanedToken\"]) \\\n",
    "      .setOutputCol(\"embeddings\")\n",
    "    \n",
    "    # Create the text classifier using ClassifierDLApproach.\n",
    "    classifier_dl = ClassifierDLApproach() \\\n",
    "      .setInputCols(['sentence_embeddings']) \\\n",
    "      .setOutputCol('prediction') \\\n",
    "      .setLabelColumn('label') \\\n",
    "      .setBatchSize(comb[\"batchSize\"]) \\\n",
    "      .setMaxEpochs(comb[\"maxEpochs\"]) \\\n",
    "      .setLr(comb[\"lr\"]) \\\n",
    "      .setDropout(comb[\"dropout\"]) \\\n",
    "      .setEnableOutputLogs(True)\n",
    "\n",
    "\n",
    "    # Creating the pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "      document_assembler,\n",
    "      tokenizer,\n",
    "      stops,\n",
    "      embeddings,\n",
    "      sentence_embeddings,\n",
    "      label_indexer,\n",
    "      classifier_dl\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predicted = model_pipeline.transform(train).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "    test_predicted = model_pipeline.transform(test).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "\n",
    "    # Initialize the evaluators\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the train set\n",
    "    train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "    train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "    train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the test set\n",
    "    test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "    test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "    test_f1 = evaluator_f1.evaluate(test_predicted)\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    result = {\n",
    "        'Train Precision': train_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Train F1 Score': train_f1,\n",
    "        'Test Precision': test_precision,\n",
    "        'Test Recall': test_recall,\n",
    "        'Test F1 Score': test_f1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(result, index=[0])\n",
    "\n",
    "# Define the hyperparameter options for each model\n",
    "hyperparameter_options = {\n",
    "    'glove_100d': {\n",
    "            'batchSize': [32, 64],\n",
    "            'dropout': [0, 0.2, 0.4],\n",
    "            'lr': [0.001, 0.01, 0.1],\n",
    "            'maxEpochs': [20]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the results DataFrame combining the metrics and parameter combinations\n",
    "combinations = []\n",
    "for key, options in hyperparameter_options.items():\n",
    "    keys = options.keys()\n",
    "    values = options.values()\n",
    "    param_combinations = [dict(zip(keys, param_values)) for param_values in itertools.product(*values)]\n",
    "    for combination in param_combinations:\n",
    "        combination['model'] = key\n",
    "        combinations.append(combination)\n",
    "\n",
    "dla_results = pd.DataFrame()\n",
    "for comb in combinations:\n",
    "    dla_results = pd.concat([dla_results.reset_index(drop = True), fit_model(comb)], axis = 0)\n",
    "    \n",
    "dla_results = pd.concat([dla_results.reset_index(drop = True), pd.DataFrame(combinations).reset_index(drop = True)], axis = 1, ignore_index=True)\n",
    "\n",
    "new_column_names = {0:'train_acc', 1:'train_rec', 2:'train_f1', 3:'test_acc', 4:'test_rec', 5:'test_f1', 6:'batch_size', 7:'dropout', 8:'lr', 9:'epochs'}\n",
    "dla_results.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "dla_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf08e7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937948</td>\n",
       "      <td>0.935705</td>\n",
       "      <td>0.934658</td>\n",
       "      <td>0.846281</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.839051</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942711</td>\n",
       "      <td>0.942544</td>\n",
       "      <td>0.942131</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.924988</td>\n",
       "      <td>0.924761</td>\n",
       "      <td>0.924030</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.968541</td>\n",
       "      <td>0.968536</td>\n",
       "      <td>0.968442</td>\n",
       "      <td>0.894223</td>\n",
       "      <td>0.893855</td>\n",
       "      <td>0.894010</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.929276</td>\n",
       "      <td>0.928865</td>\n",
       "      <td>0.928137</td>\n",
       "      <td>0.871941</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.871696</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.904237</td>\n",
       "      <td>0.904241</td>\n",
       "      <td>0.903160</td>\n",
       "      <td>0.882379</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.882501</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.978218</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.978037</td>\n",
       "      <td>0.876456</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.872625</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.130429</td>\n",
       "      <td>0.361149</td>\n",
       "      <td>0.191645</td>\n",
       "      <td>0.140102</td>\n",
       "      <td>0.374302</td>\n",
       "      <td>0.203888</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.952131</td>\n",
       "      <td>0.952120</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.882379</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.882501</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.931725</td>\n",
       "      <td>0.931601</td>\n",
       "      <td>0.931040</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.965800</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.859962</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.860121</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.941394</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.940724</td>\n",
       "      <td>0.870784</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.908009</td>\n",
       "      <td>0.908345</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.967279</td>\n",
       "      <td>0.967168</td>\n",
       "      <td>0.967025</td>\n",
       "      <td>0.883082</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.882853</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.926478</td>\n",
       "      <td>0.926129</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.909549</td>\n",
       "      <td>0.909713</td>\n",
       "      <td>0.908882</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "0    0.937948   0.935705  0.934658  0.846281  0.843575  0.839051          32  \\\n",
       "1    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "2    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "3    0.942711   0.942544  0.942131  0.865922  0.865922  0.865922          32   \n",
       "4    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "5    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "6    0.924988   0.924761  0.924030  0.877095  0.877095  0.877095          32   \n",
       "7    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "8    0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "9    0.968541   0.968536  0.968442  0.894223  0.893855  0.894010          64   \n",
       "10   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "11   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "12   0.929276   0.928865  0.928137  0.871941  0.871508  0.871696          64   \n",
       "13   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "14   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "15   0.904237   0.904241  0.903160  0.882379  0.882682  0.882501          64   \n",
       "16   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "17   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "18   0.978218   0.978112  0.978037  0.876456  0.871508  0.872625          16   \n",
       "19   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          16   \n",
       "20   0.130429   0.361149  0.191645  0.140102  0.374302  0.203888          16   \n",
       "21   0.952131   0.952120  0.951890  0.882379  0.882682  0.882501          16   \n",
       "22   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          16   \n",
       "23   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          16   \n",
       "24   0.931725   0.931601  0.931040  0.865922  0.865922  0.865922          16   \n",
       "25   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          16   \n",
       "26   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          16   \n",
       "27   0.965854   0.965800  0.965667  0.859962  0.860335  0.860121          32   \n",
       "28   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "29   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "30   0.941394   0.941176  0.940724  0.870784  0.871508  0.870886          32   \n",
       "31   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "32   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "33   0.908009   0.908345  0.907639  0.854749  0.854749  0.854749          32   \n",
       "34   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "35   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "36   0.967279   0.967168  0.967025  0.883082  0.882682  0.882853          64   \n",
       "37   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "38   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "39   0.926478   0.926129  0.925373  0.865922  0.865922  0.865922          64   \n",
       "40   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "41   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "42   0.909549   0.909713  0.908882  0.865922  0.865922  0.865922          64   \n",
       "43   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "44   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "\n",
       "    dropout     lr  epochs                                                 10  \n",
       "0       0.0  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "1       0.0  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "2       0.0  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "3       0.2  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "4       0.2  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "5       0.2  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "6       0.4  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "7       0.4  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "8       0.4  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "9       0.0  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "10      0.0  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "11      0.0  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "12      0.2  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "13      0.2  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "14      0.2  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "15      0.4  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "16      0.4  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "17      0.4  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "18      0.0  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "19      0.0  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "20      0.0  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "21      0.2  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "22      0.2  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "23      0.2  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "24      0.4  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "25      0.4  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "26      0.4  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "27      0.0  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "28      0.0  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "29      0.0  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "30      0.2  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "31      0.2  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "32      0.2  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "33      0.4  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "34      0.4  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "35      0.4  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "36      0.0  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "37      0.0  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "38      0.0  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "39      0.2  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "40      0.2  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "41      0.2  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "42      0.4  0.001      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "43      0.4  0.010      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "44      0.4  0.100      20   roberta_embeddings_pmc_med_bio_mlm_roberta_large  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_results = dla_results\n",
    "glove_results.sort_values(by = [\"test_f1\"], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a87e275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'W5K4692K475D74XN',\n",
       "  'HostId': 'WLAuxSSgE2pOHanSUprNbLdnm6Ng54/CV1QsT3fdvpVCOy+Hg14gzcf5X6clGPz8vZSQYJ85Agw=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'WLAuxSSgE2pOHanSUprNbLdnm6Ng54/CV1QsT3fdvpVCOy+Hg14gzcf5X6clGPz8vZSQYJ85Agw=',\n",
       "   'x-amz-request-id': 'W5K4692K475D74XN',\n",
       "   'date': 'Mon, 03 Jul 2023 21:05:00 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"eca39077cd0f96bbe0486a3da11e29a4\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"eca39077cd0f96bbe0486a3da11e29a4\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV format in memory.\n",
    "csv_buffer = glove_results.to_csv(index=False).encode()\n",
    "\n",
    "# Create an instance of the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Sepcify file name and route in the S3\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'binary_glove_results_balanced_S3_total.csv'\n",
    "\n",
    "# Uppload file to the S3 bucket\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=bucket_name, Key=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63799f",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d3e5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[ | ]stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[ | ]bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[ \\ ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:========================================>                (23 + 4) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:23:01.676032: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.lang.ref.Reference.referent\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:25:36.272441: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/d40f5b8eba89_classifier_dl1371986364961546665\n",
      "2023-07-07 11:25:36.339544: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:25:36.339596: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/d40f5b8eba89_classifier_dl1371986364961546665\n",
      "2023-07-07 11:25:36.833815: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:25:38.017626: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/d40f5b8eba89_classifier_dl1371986364961546665\n",
      "2023-07-07 11:25:38.304033: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2031599 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.56s - loss: 12.305529 - acc: 0.84464437 - batches: 23\n",
      "Epoch 2/20 - 0.19s - loss: 9.343289 - acc: 1.0 - batches: 23\n",
      "Epoch 3/20 - 0.20s - loss: 9.304804 - acc: 1.0 - batches: 23\n",
      "Epoch 4/20 - 0.25s - loss: 9.52035 - acc: 1.0 - batches: 23\n",
      "Epoch 5/20 - 0.22s - loss: 8.709579 - acc: 1.0 - batches: 23\n",
      "Epoch 6/20 - 0.17s - loss: 8.282877 - acc: 1.0 - batches: 23\n",
      "Epoch 7/20 - 0.17s - loss: 8.313416 - acc: 1.0 - batches: 23\n",
      "Epoch 8/20 - 0.20s - loss: 8.222092 - acc: 1.0 - batches: 23\n",
      "Epoch 9/20 - 0.17s - loss: 8.220557 - acc: 1.0 - batches: 23\n",
      "Epoch 10/20 - 0.17s - loss: 8.217948 - acc: 1.0 - batches: 23\n",
      "Epoch 11/20 - 0.16s - loss: 8.214332 - acc: 1.0 - batches: 23\n",
      "Epoch 12/20 - 0.17s - loss: 8.21314 - acc: 1.0 - batches: 23\n",
      "Epoch 13/20 - 0.16s - loss: 8.211519 - acc: 1.0 - batches: 23\n",
      "Epoch 14/20 - 0.16s - loss: 8.21046 - acc: 1.0 - batches: 23\n",
      "Epoch 15/20 - 0.16s - loss: 8.209468 - acc: 1.0 - batches: 23\n",
      "Epoch 16/20 - 0.18s - loss: 8.208488 - acc: 1.0 - batches: 23\n",
      "Epoch 17/20 - 0.17s - loss: 8.207536 - acc: 1.0 - batches: 23\n",
      "Epoch 18/20 - 0.16s - loss: 8.207381 - acc: 1.0 - batches: 23\n",
      "Epoch 19/20 - 0.16s - loss: 8.208885 - acc: 1.0 - batches: 23\n",
      "Epoch 20/20 - 0.17s - loss: 8.207833 - acc: 1.0 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:32:02.079889: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/87352abaa69e_classifier_dl3191154404112919142\n",
      "2023-07-07 11:32:02.173714: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:32:02.173773: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/87352abaa69e_classifier_dl3191154404112919142\n",
      "2023-07-07 11:32:02.744585: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:32:04.062943: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/87352abaa69e_classifier_dl3191154404112919142\n",
      "2023-07-07 11:32:04.379152: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2299274 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.72s - loss: 13.699125 - acc: 0.65388256 - batches: 23\n",
      "Epoch 2/20 - 0.24s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 3/20 - 0.22s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 4/20 - 0.18s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 5/20 - 0.17s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 6/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 7/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 8/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 9/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 10/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 11/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 12/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 13/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 14/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 15/20 - 0.16s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 16/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 17/20 - 0.15s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 13.205021 - acc: 0.6680871 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:38:21.626553: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/670b40976827_classifier_dl1833213988816781405\n",
      "2023-07-07 11:38:21.733578: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:38:21.733636: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/670b40976827_classifier_dl1833213988816781405\n",
      "2023-07-07 11:38:22.313100: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:38:23.446230: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/670b40976827_classifier_dl1833213988816781405\n",
      "2023-07-07 11:38:23.653949: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2027407 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.51s - loss: 15.514033 - acc: 0.65930134 - batches: 23\n",
      "Epoch 2/20 - 0.19s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 3/20 - 0.16s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 4/20 - 0.15s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 5/20 - 0.18s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 6/20 - 0.18s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 7/20 - 0.19s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 8/20 - 0.16s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n",
      "Epoch 20/20 - 0.13s - loss: 16.20502 - acc: 0.66782403 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:44:40.739002: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/89de841c520f_classifier_dl1378691127933742264\n",
      "2023-07-07 11:44:40.863297: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:44:40.863359: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/89de841c520f_classifier_dl1378691127933742264\n",
      "2023-07-07 11:44:41.476429: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:44:42.713674: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/89de841c520f_classifier_dl1378691127933742264\n",
      "2023-07-07 11:44:42.935812: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2196821 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.52s - loss: 13.718888 - acc: 0.80087334 - batches: 23\n",
      "Epoch 2/20 - 0.14s - loss: 7.9460135 - acc: 1.0 - batches: 23\n",
      "Epoch 3/20 - 0.14s - loss: 7.41991 - acc: 1.0 - batches: 23\n",
      "Epoch 4/20 - 0.14s - loss: 7.343058 - acc: 1.0 - batches: 23\n",
      "Epoch 5/20 - 0.14s - loss: 7.284739 - acc: 1.0 - batches: 23\n",
      "Epoch 6/20 - 0.14s - loss: 7.2538576 - acc: 1.0 - batches: 23\n",
      "Epoch 7/20 - 0.14s - loss: 7.2387557 - acc: 1.0 - batches: 23\n",
      "Epoch 8/20 - 0.14s - loss: 7.2378078 - acc: 1.0 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 7.234321 - acc: 1.0 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 7.2301154 - acc: 1.0 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 7.2275968 - acc: 1.0 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 7.224295 - acc: 1.0 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 7.222399 - acc: 1.0 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 7.2201934 - acc: 1.0 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 7.2186356 - acc: 1.0 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 7.2171526 - acc: 1.0 - batches: 23\n",
      "Epoch 17/20 - 0.15s - loss: 7.2161584 - acc: 1.0 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 7.215331 - acc: 1.0 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 7.214186 - acc: 1.0 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 7.21318 - acc: 1.0 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:50:56.745058: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/cc43c1b066b7_classifier_dl17156179952466690496\n",
      "2023-07-07 11:50:56.806041: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:50:56.806100: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/cc43c1b066b7_classifier_dl17156179952466690496\n",
      "2023-07-07 11:50:57.344449: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:50:58.462877: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/cc43c1b066b7_classifier_dl17156179952466690496\n",
      "2023-07-07 11:50:58.643322: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1898275 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.52s - loss: 18.677586 - acc: 0.65956444 - batches: 23\n",
      "Epoch 2/20 - 0.15s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 3/20 - 0.15s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 4/20 - 0.15s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 5/20 - 0.15s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 6/20 - 0.19s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 7/20 - 0.16s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 8/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 18.20502 - acc: 0.6680871 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 11:57:07.726987: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/e9a8d61572f7_classifier_dl17289382700135340299\n",
      "2023-07-07 11:57:07.818738: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 11:57:07.818795: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/e9a8d61572f7_classifier_dl17289382700135340299\n",
      "2023-07-07 11:57:08.382261: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 11:57:09.569466: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/e9a8d61572f7_classifier_dl17289382700135340299\n",
      "2023-07-07 11:57:09.922797: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2195827 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.67s - loss: 18.458485 - acc: 0.6474116 - batches: 23\n",
      "Epoch 2/20 - 0.15s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 3/20 - 0.16s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 4/20 - 0.15s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 5/20 - 0.15s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 6/20 - 0.15s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 7/20 - 0.16s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 8/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 19.205019 - acc: 0.66729796 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:03:26.541555: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/4d24acca0aae_classifier_dl10456502857029084131\n",
      "2023-07-07 12:03:26.603446: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:03:26.603508: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/4d24acca0aae_classifier_dl10456502857029084131\n",
      "2023-07-07 12:03:27.154459: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:03:28.349407: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/4d24acca0aae_classifier_dl10456502857029084131\n",
      "2023-07-07 12:03:28.580940: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2039398 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.49s - loss: 10.403878 - acc: 0.856271 - batches: 23\n",
      "Epoch 2/20 - 0.17s - loss: 7.7511854 - acc: 1.0 - batches: 23\n",
      "Epoch 3/20 - 0.18s - loss: 7.5122623 - acc: 1.0 - batches: 23\n",
      "Epoch 4/20 - 0.18s - loss: 7.3919053 - acc: 1.0 - batches: 23\n",
      "Epoch 5/20 - 0.17s - loss: 7.635238 - acc: 1.0 - batches: 23\n",
      "Epoch 6/20 - 0.18s - loss: 7.4198647 - acc: 1.0 - batches: 23\n",
      "Epoch 7/20 - 0.17s - loss: 7.3634577 - acc: 1.0 - batches: 23\n",
      "Epoch 8/20 - 0.14s - loss: 7.347785 - acc: 1.0 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 7.3363376 - acc: 1.0 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 7.3207874 - acc: 1.0 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 7.3065033 - acc: 1.0 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 7.2947187 - acc: 1.0 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 7.2862844 - acc: 1.0 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 7.2793684 - acc: 1.0 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 7.273947 - acc: 1.0 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 7.2696257 - acc: 1.0 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 7.2660418 - acc: 1.0 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 7.263 - acc: 1.0 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 7.260289 - acc: 1.0 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 7.257974 - acc: 1.0 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:09:39.813073: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/cdeb014f87bf_classifier_dl13901708638249703304\n",
      "2023-07-07 12:09:39.935361: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:09:39.935417: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/cdeb014f87bf_classifier_dl13901708638249703304\n",
      "2023-07-07 12:09:40.572672: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:09:41.703260: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/cdeb014f87bf_classifier_dl13901708638249703304\n",
      "2023-07-07 12:09:42.084163: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2271101 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.59s - loss: 15.728164 - acc: 0.6536195 - batches: 23\n",
      "Epoch 2/20 - 0.23s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 3/20 - 0.19s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 4/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 5/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 6/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 7/20 - 0.13s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 8/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 19/20 - 0.13s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 15.205021 - acc: 0.66782403 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:15:49.558346: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/9934c113d501_classifier_dl11497625621605749251\n",
      "2023-07-07 12:15:49.691442: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:15:49.691501: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/9934c113d501_classifier_dl11497625621605749251\n",
      "2023-07-07 12:15:50.364467: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:15:51.629461: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/9934c113d501_classifier_dl11497625621605749251\n",
      "2023-07-07 12:15:51.945692: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2387358 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 32 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.65s - loss: 13.471944 - acc: 0.6629314 - batches: 23\n",
      "Epoch 2/20 - 0.19s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 3/20 - 0.16s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 4/20 - 0.16s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 5/20 - 0.18s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 6/20 - 0.16s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 7/20 - 0.17s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 8/20 - 0.16s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 9/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 10/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 11/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 12/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 13/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 14/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 15/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 16/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 17/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 18/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 19/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n",
      "Epoch 20/20 - 0.14s - loss: 14.205022 - acc: 0.6686132 - batches: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:22:07.750498: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/cc8140630591_classifier_dl147479064812073180\n",
      "2023-07-07 12:22:07.816635: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:22:07.816686: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/cc8140630591_classifier_dl147479064812073180\n",
      "2023-07-07 12:22:08.381764: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:22:09.524351: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/cc8140630591_classifier_dl147479064812073180\n",
      "2023-07-07 12:22:09.777504: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2027016 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.62s - loss: 6.8691764 - acc: 0.72180134 - batches: 12\n",
      "Epoch 2/20 - 0.20s - loss: 4.6828933 - acc: 1.0 - batches: 12\n",
      "Epoch 3/20 - 0.24s - loss: 3.8571274 - acc: 1.0 - batches: 12\n",
      "Epoch 4/20 - 0.09s - loss: 4.034831 - acc: 1.0 - batches: 12\n",
      "Epoch 5/20 - 0.08s - loss: 3.7666283 - acc: 1.0 - batches: 12\n",
      "Epoch 6/20 - 0.08s - loss: 3.763808 - acc: 1.0 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 3.7619722 - acc: 1.0 - batches: 12\n",
      "Epoch 8/20 - 0.08s - loss: 3.7618313 - acc: 1.0 - batches: 12\n",
      "Epoch 9/20 - 0.08s - loss: 3.7614956 - acc: 1.0 - batches: 12\n",
      "Epoch 10/20 - 0.08s - loss: 3.7613778 - acc: 1.0 - batches: 12\n",
      "Epoch 11/20 - 0.08s - loss: 3.760907 - acc: 1.0 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 3.760552 - acc: 1.0 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 3.760449 - acc: 1.0 - batches: 12\n",
      "Epoch 14/20 - 0.08s - loss: 3.7605755 - acc: 1.0 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 3.760409 - acc: 1.0 - batches: 12\n",
      "Epoch 16/20 - 0.08s - loss: 3.7603714 - acc: 1.0 - batches: 12\n",
      "Epoch 17/20 - 0.08s - loss: 3.7601438 - acc: 1.0 - batches: 12\n",
      "Epoch 18/20 - 0.09s - loss: 3.759928 - acc: 1.0 - batches: 12\n",
      "Epoch 19/20 - 0.08s - loss: 3.7598834 - acc: 1.0 - batches: 12\n",
      "Epoch 20/20 - 0.08s - loss: 3.75977 - acc: 1.0 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:28:22.267975: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/a50391b39f76_classifier_dl13251375626230369602\n",
      "2023-07-07 12:28:22.358991: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:28:22.359049: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/a50391b39f76_classifier_dl13251375626230369602\n",
      "2023-07-07 12:28:22.911391: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:28:24.108200: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/a50391b39f76_classifier_dl13251375626230369602\n",
      "2023-07-07 12:28:24.421208: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2153244 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.94s - loss: 7.0415044 - acc: 0.69091964 - batches: 12\n",
      "Epoch 2/20 - 0.11s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 3/20 - 0.16s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 4/20 - 0.16s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 5/20 - 0.12s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 6/20 - 0.17s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 7/20 - 0.13s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 8/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 15/20 - 0.10s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 18/20 - 0.10s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 7.759139 - acc: 0.70228326 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:34:59.824054: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/9833d5fcabbf_classifier_dl5100020277161443195\n",
      "2023-07-07 12:34:59.943827: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:34:59.943885: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/9833d5fcabbf_classifier_dl5100020277161443195\n",
      "2023-07-07 12:35:00.692164: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:35:02.116637: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/9833d5fcabbf_classifier_dl5100020277161443195\n",
      "2023-07-07 12:35:02.344846: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2520803 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.68s - loss: 8.255995 - acc: 0.65561867 - batches: 12\n",
      "Epoch 2/20 - 0.21s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 3/20 - 0.20s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 4/20 - 0.17s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 5/20 - 0.19s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 6/20 - 0.21s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 7/20 - 0.13s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 8/20 - 0.12s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 9/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 10/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 11/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 12/20 - 0.10s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 13/20 - 0.13s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 14/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 15/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 16/20 - 0.11s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 17/20 - 0.10s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 18/20 - 0.17s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 19/20 - 0.16s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n",
      "Epoch 20/20 - 0.17s - loss: 7.7591395 - acc: 0.6925505 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:41:28.098256: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/57bf0a1bdbf6_classifier_dl2859146096876657103\n",
      "2023-07-07 12:41:28.219718: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:41:28.219778: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/57bf0a1bdbf6_classifier_dl2859146096876657103\n",
      "2023-07-07 12:41:28.843451: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:41:30.118296: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/57bf0a1bdbf6_classifier_dl2859146096876657103\n",
      "2023-07-07 12:41:30.341496: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2243252 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.49s - loss: 6.7248654 - acc: 0.7738321 - batches: 12\n",
      "Epoch 2/20 - 0.09s - loss: 4.602114 - acc: 1.0 - batches: 12\n",
      "Epoch 3/20 - 0.08s - loss: 3.9243286 - acc: 1.0 - batches: 12\n",
      "Epoch 4/20 - 0.08s - loss: 3.8949008 - acc: 1.0 - batches: 12\n",
      "Epoch 5/20 - 0.08s - loss: 3.8027585 - acc: 1.0 - batches: 12\n",
      "Epoch 6/20 - 0.08s - loss: 3.8534863 - acc: 1.0 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 3.800314 - acc: 1.0 - batches: 12\n",
      "Epoch 8/20 - 0.09s - loss: 3.8037562 - acc: 1.0 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 3.7984195 - acc: 1.0 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 3.7889023 - acc: 1.0 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 3.785223 - acc: 1.0 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 3.782368 - acc: 1.0 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 3.7798243 - acc: 1.0 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 3.7781453 - acc: 1.0 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 3.7768617 - acc: 1.0 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 3.7757745 - acc: 1.0 - batches: 12\n",
      "Epoch 17/20 - 0.08s - loss: 3.7748685 - acc: 1.0 - batches: 12\n",
      "Epoch 18/20 - 0.08s - loss: 3.7740455 - acc: 1.0 - batches: 12\n",
      "Epoch 19/20 - 0.08s - loss: 3.7732306 - acc: 1.0 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 3.7724004 - acc: 1.0 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:47:48.751077: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/8fd738850ab9_classifier_dl7164344085005379903\n",
      "2023-07-07 12:47:48.821439: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:47:48.821494: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/8fd738850ab9_classifier_dl7164344085005379903\n",
      "2023-07-07 12:47:49.374302: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:47:50.534137: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/8fd738850ab9_classifier_dl7164344085005379903\n",
      "2023-07-07 12:47:50.717706: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1966646 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.43s - loss: 7.237254 - acc: 0.66429925 - batches: 12\n",
      "Epoch 2/20 - 0.13s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 3/20 - 0.17s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 4/20 - 0.14s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 5/20 - 0.14s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 6/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 8/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 13/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 14/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 15/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 16/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 17/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 18/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 19/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n",
      "Epoch 20/20 - 0.08s - loss: 6.759139 - acc: 0.6983901 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 12:54:02.800774: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/3d7cd6ce166f_classifier_dl14187568001827034027\n",
      "2023-07-07 12:54:02.932605: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 12:54:02.932659: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/3d7cd6ce166f_classifier_dl14187568001827034027\n",
      "2023-07-07 12:54:03.588453: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 12:54:04.833498: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/3d7cd6ce166f_classifier_dl14187568001827034027\n",
      "2023-07-07 12:54:05.058070: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2257310 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.51s - loss: 6.3501124 - acc: 0.6623527 - batches: 12\n",
      "Epoch 2/20 - 0.11s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 3/20 - 0.11s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 4/20 - 0.13s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 5/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 6/20 - 0.08s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 8/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 15/20 - 0.08s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 16/20 - 0.08s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 18/20 - 0.08s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 20/20 - 0.08s - loss: 5.75914 - acc: 0.6964436 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 13:00:14.977782: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/5435337e72f8_classifier_dl8804539379611609277\n",
      "2023-07-07 13:00:15.040884: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 13:00:15.040943: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/5435337e72f8_classifier_dl8804539379611609277\n",
      "2023-07-07 13:00:15.606414: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 13:00:16.849433: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/5435337e72f8_classifier_dl8804539379611609277\n",
      "2023-07-07 13:00:17.035409: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2057638 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.49s - loss: 7.829472 - acc: 0.82938766 - batches: 12\n",
      "Epoch 2/20 - 0.16s - loss: 4.065592 - acc: 1.0 - batches: 12\n",
      "Epoch 3/20 - 0.14s - loss: 3.814427 - acc: 1.0 - batches: 12\n",
      "Epoch 4/20 - 0.17s - loss: 3.7759175 - acc: 1.0 - batches: 12\n",
      "Epoch 5/20 - 0.17s - loss: 3.7684524 - acc: 1.0 - batches: 12\n",
      "Epoch 6/20 - 0.17s - loss: 3.7676525 - acc: 1.0 - batches: 12\n",
      "Epoch 7/20 - 0.15s - loss: 3.7664547 - acc: 1.0 - batches: 12\n",
      "Epoch 8/20 - 0.11s - loss: 3.7652886 - acc: 1.0 - batches: 12\n",
      "Epoch 9/20 - 0.10s - loss: 3.7648644 - acc: 1.0 - batches: 12\n",
      "Epoch 10/20 - 0.08s - loss: 3.764496 - acc: 1.0 - batches: 12\n",
      "Epoch 11/20 - 0.08s - loss: 3.7641263 - acc: 1.0 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 3.7638402 - acc: 1.0 - batches: 12\n",
      "Epoch 13/20 - 0.08s - loss: 3.7636094 - acc: 1.0 - batches: 12\n",
      "Epoch 14/20 - 0.08s - loss: 3.7634103 - acc: 1.0 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 3.763235 - acc: 1.0 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 3.7630894 - acc: 1.0 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 3.762971 - acc: 1.0 - batches: 12\n",
      "Epoch 18/20 - 0.09s - loss: 3.7628677 - acc: 1.0 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 3.762776 - acc: 1.0 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 3.762695 - acc: 1.0 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 13:06:33.372155: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/4a7c3a37f6e1_classifier_dl16684624843572222650\n",
      "2023-07-07 13:06:33.514105: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 13:06:33.514158: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/4a7c3a37f6e1_classifier_dl16684624843572222650\n",
      "2023-07-07 13:06:34.189145: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 13:06:35.408902: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/4a7c3a37f6e1_classifier_dl16684624843572222650\n",
      "2023-07-07 13:06:35.638241: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2266104 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.59s - loss: 9.20238 - acc: 0.6595118 - batches: 12\n",
      "Epoch 2/20 - 0.17s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 3/20 - 0.15s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 4/20 - 0.24s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 5/20 - 0.15s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 6/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 8/20 - 0.08s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 18/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n",
      "Epoch 20/20 - 0.08s - loss: 8.75914 - acc: 0.6964436 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 13:12:50.598823: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/8a737a90d711_classifier_dl6230063465910928981\n",
      "2023-07-07 13:12:50.759704: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 13:12:50.759756: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/8a737a90d711_classifier_dl6230063465910928981\n",
      "2023-07-07 13:12:51.529039: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 13:12:53.096931: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/8a737a90d711_classifier_dl6230063465910928981\n",
      "2023-07-07 13:12:53.325336: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2738777 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.60s - loss: 5.2532434 - acc: 0.6604062 - batches: 12\n",
      "Epoch 2/20 - 0.17s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 3/20 - 0.17s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 4/20 - 0.13s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 5/20 - 0.10s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 6/20 - 0.10s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 7/20 - 0.10s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 8/20 - 0.10s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 9/20 - 0.10s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 18/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 4.75914 - acc: 0.69449705 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991829</td>\n",
       "      <td>0.991792</td>\n",
       "      <td>0.991778</td>\n",
       "      <td>0.972213</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.972108</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.408130</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "0   0.991829   0.991792  0.991778  0.972213  0.972067  0.972108          32  \\\n",
       "1   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "2   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "3   0.993179   0.993160  0.993151  0.978038  0.977654  0.977717          32   \n",
       "4   0.408130   0.638851  0.498069  0.391498  0.625698  0.481637          32   \n",
       "\n",
       "   dropout     lr  epochs                                                 10  \n",
       "0      0.0  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "1      0.0  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "2      0.0  0.100      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "3      0.2  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "4      0.2  0.010      20  bert_embeddings_bert_large_uncased_whole_word_...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we define the modules that will compose the NLP pipeline, \n",
    "# next we create a function to train different models with different\n",
    "# hyperparameter combinations while saving the results in a dataframe\n",
    "\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "# Define the assembler\n",
    "document_assembler = DocumentAssembler().setInputCol('frase_traducida').setOutputCol('document')\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n",
    "\n",
    "# Define the stopword remover\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    ".setInputCols(\"token\")\\\n",
    ".setOutputCol(\"cleanedToken\")\n",
    "\n",
    "# Create the sentence embeddings feature extractor\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "  .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"sentence_embeddings\") \\\n",
    "  .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "def fit_model(epochs):\n",
    "    \n",
    "    # Create the feature extractor using BERT word embeddings\n",
    "    embeddings = BertEmbeddings.pretrained(\"bert_embeddings_bert_large_uncased_whole_word_masking\", \"en\") \\\n",
    "      .setInputCols([\"document\", \"cleanedToken\"]) \\\n",
    "      .setOutputCol(\"embeddings\")\n",
    "    \n",
    "    # Create the text classifier using ClassifierDLApproach.\n",
    "    classifier_dl = ClassifierDLApproach() \\\n",
    "      .setInputCols(['sentence_embeddings']) \\\n",
    "      .setOutputCol('prediction') \\\n",
    "      .setLabelColumn('label') \\\n",
    "      .setBatchSize(comb[\"batchSize\"]) \\\n",
    "      .setMaxEpochs(comb[\"maxEpochs\"]) \\\n",
    "      .setLr(comb[\"lr\"]) \\\n",
    "      .setDropout(comb[\"dropout\"]) \\\n",
    "      .setEnableOutputLogs(True)\n",
    "\n",
    "\n",
    "    # Creating the pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "      document_assembler,\n",
    "      tokenizer,\n",
    "      stops,\n",
    "      embeddings,\n",
    "      sentence_embeddings,\n",
    "      label_indexer,\n",
    "      classifier_dl\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predicted = model_pipeline.transform(train).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "    test_predicted = model_pipeline.transform(test).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "\n",
    "    # Initialize the evaluators\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the train set\n",
    "    train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "    train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "    train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the test set\n",
    "    test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "    test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "    test_f1 = evaluator_f1.evaluate(test_predicted)\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    result = {\n",
    "        'Train Precision': train_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Train F1 Score': train_f1,\n",
    "        'Test Precision': test_precision,\n",
    "        'Test Recall': test_recall,\n",
    "        'Test F1 Score': test_f1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(result, index=[0])\n",
    "\n",
    "# Define the hyperparameter options for each model\n",
    "hyperparameter_options = {\n",
    "    'bert_embeddings_bert_large_uncased_whole_word_masking': {\n",
    "            'batchSize': [32, 64],\n",
    "            'dropout': [0, 0.2, 0.4],\n",
    "            'lr': [0.001, 0.01, 0.1],\n",
    "            'maxEpochs': [20]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the results DataFrame combining the metrics and parameter combinations\n",
    "combinations = []\n",
    "for key, options in hyperparameter_options.items():\n",
    "    keys = options.keys()\n",
    "    values = options.values()\n",
    "    param_combinations = [dict(zip(keys, param_values)) for param_values in itertools.product(*values)]\n",
    "    for combination in param_combinations:\n",
    "        combination['model'] = key\n",
    "        combinations.append(combination)\n",
    "\n",
    "dla_results = pd.DataFrame()\n",
    "for comb in combinations:\n",
    "    dla_results = pd.concat([dla_results.reset_index(drop = True), fit_model(comb)], axis = 0)\n",
    "    \n",
    "dla_results = pd.concat([dla_results.reset_index(drop = True), pd.DataFrame(combinations).reset_index(drop = True)], axis = 1, ignore_index=True)\n",
    "\n",
    "new_column_names = {0:'train_acc', 1:'train_rec', 2:'train_f1', 3:'test_acc', 4:'test_rec', 5:'test_f1', 6:'batch_size', 7:'dropout', 8:'lr', 9:'epochs'}\n",
    "dla_results.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "dla_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb9eecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.989146</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>0.989028</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993179</td>\n",
       "      <td>0.993160</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>0.977654</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.986320</td>\n",
       "      <td>0.986285</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.972183</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.986320</td>\n",
       "      <td>0.986285</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.972183</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.986320</td>\n",
       "      <td>0.986285</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>0.972183</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>bert_embeddings_bert_large_uncased_whole_word_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "9    0.989146   0.989056  0.989028  0.978038  0.977654  0.977717          64  \\\n",
       "3    0.993179   0.993160  0.993151  0.978038  0.977654  0.977717          32   \n",
       "6    0.986395   0.986320  0.986285  0.972871  0.972067  0.972183          32   \n",
       "15   0.986395   0.986320  0.986285  0.972871  0.972067  0.972183          64   \n",
       "12   0.986395   0.986320  0.986285  0.972871  0.972067  0.972183          64   \n",
       "\n",
       "    dropout     lr  epochs                                                 10  \n",
       "9       0.0  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "3       0.2  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "6       0.4  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "15      0.4  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  \n",
       "12      0.2  0.001      20  bert_embeddings_bert_large_uncased_whole_word_...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_results = dla_results\n",
    "bert_results.sort_values(by = [\"test_f1\"], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd643d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'G9V0RX6DAC2H0FDS',\n",
       "  'HostId': '5HZpiuyuIiTQ0VRYuJXosHir1m0Vmkq90mfw54JQNm5qkSvLEyUX0iFsemYwQMTrabBWpJI48rmLZhb0D1J/+ae80pG79+75yVOJxKzaKkU=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '5HZpiuyuIiTQ0VRYuJXosHir1m0Vmkq90mfw54JQNm5qkSvLEyUX0iFsemYwQMTrabBWpJI48rmLZhb0D1J/+ae80pG79+75yVOJxKzaKkU=',\n",
       "   'x-amz-request-id': 'G9V0RX6DAC2H0FDS',\n",
       "   'date': 'Fri, 07 Jul 2023 13:18:38 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"c6449fea3e4b10539131e7dc036d2c35\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"c6449fea3e4b10539131e7dc036d2c35\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV format in memory.\n",
    "csv_buffer = bert_results.to_csv(index=False).encode()\n",
    "\n",
    "# Create an instance of the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Sepcify file name and route in the S3\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'binary_bert_results_balanced_S3_total.csv'\n",
    "\n",
    "# Uppload file to the S3 bucket\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=bucket_name, Key=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b3782",
   "metadata": {},
   "source": [
    "## BIO-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "916e4a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[ | ]stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_embeddings_pmc_med_bio_mlm_roberta_large download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[ | ]roberta_embeddings_pmc_med_bio_mlm_roberta_large download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[ | ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:===================================>                     (20 + 4) / 32]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 18:15:45.179918: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.3.1.jar) to field java.lang.ref.Reference.referent\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 18:19:02.808901: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/543e3ef57c25_classifier_dl6726401380524925563\n",
      "2023-07-07 18:19:02.864942: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 18:19:02.865004: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/543e3ef57c25_classifier_dl6726401380524925563\n",
      "2023-07-07 18:19:03.345159: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 18:19:04.500976: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/543e3ef57c25_classifier_dl6726401380524925563\n",
      "2023-07-07 18:19:04.685546: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1876651 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.61s - loss: 11.358751 - acc: 0.6500947 - batches: 12\n",
      "Epoch 2/20 - 0.12s - loss: 10.759133 - acc: 0.6983901 - batches: 12\n",
      "Epoch 3/20 - 0.11s - loss: 10.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 4/20 - 0.11s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 5/20 - 0.12s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 6/20 - 0.12s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 8/20 - 0.10s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 9/20 - 0.11s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 10/20 - 0.11s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 11/20 - 0.10s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 12/20 - 0.12s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 13/20 - 0.10s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 18/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 19/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 10.759141 - acc: 0.6983901 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_embeddings_pmc_med_bio_mlm_roberta_large download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 18:27:19.475876: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/99072950f735_classifier_dl4552652037971582484\n",
      "2023-07-07 18:27:19.564465: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 18:27:19.564521: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/99072950f735_classifier_dl4552652037971582484\n",
      "2023-07-07 18:27:20.110643: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 18:27:21.268790: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/99072950f735_classifier_dl4552652037971582484\n",
      "2023-07-07 18:27:21.472692: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1996827 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.01 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.49s - loss: 7.953333 - acc: 0.6756629 - batches: 12\n",
      "Epoch 2/20 - 0.11s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 3/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 4/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 5/20 - 0.11s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 6/20 - 0.10s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 8/20 - 0.10s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 9/20 - 0.10s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 10/20 - 0.12s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 12/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 14/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 16/20 - 0.08s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 17/20 - 0.08s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 18/20 - 0.08s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 19/20 - 0.08s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n",
      "Epoch 20/20 - 0.09s - loss: 8.75914 - acc: 0.6983901 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_embeddings_pmc_med_bio_mlm_roberta_large download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 18:35:38.084646: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/9502bb574d8b_classifier_dl8876844545407570390\n",
      "2023-07-07 18:35:38.192625: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-07 18:35:38.192680: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/9502bb574d8b_classifier_dl8876844545407570390\n",
      "2023-07-07 18:35:38.776616: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-07 18:35:39.980212: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/9502bb574d8b_classifier_dl8876844545407570390\n",
      "2023-07-07 18:35:40.320356: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2235724 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.1 - batch_size: 64 - training_examples: 731 - classes: 2\n",
      "Epoch 1/20 - 0.66s - loss: 6.4049034 - acc: 0.66998106 - batches: 12\n",
      "Epoch 2/20 - 0.12s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 3/20 - 0.12s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 4/20 - 0.12s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 5/20 - 0.13s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 6/20 - 0.11s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 7/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 8/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 9/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 10/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 11/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 12/20 - 0.11s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 13/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 14/20 - 0.10s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 15/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 16/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 17/20 - 0.09s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 18/20 - 0.08s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 19/20 - 0.08s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n",
      "Epoch 20/20 - 0.08s - loss: 5.7591395 - acc: 0.6983901 - batches: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "0    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64  \\\n",
       "1    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "2    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "\n",
       "   dropout     lr  epochs                                                10  \n",
       "0      0.4  0.001      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "1      0.4  0.010      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "2      0.4  0.100      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we define the modules that will compose the NLP pipeline, \n",
    "# next we create a function to train different models with different\n",
    "# hyperparameter combinations while saving the results in a dataframe\n",
    "\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "# Define the assembler\n",
    "document_assembler = DocumentAssembler().setInputCol('frase_traducida').setOutputCol('document')\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n",
    "\n",
    "# Define the stopword remover\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    ".setInputCols(\"token\")\\\n",
    ".setOutputCol(\"cleanedToken\")\n",
    "\n",
    "# Create the sentence embeddings feature extractor\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "  .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"sentence_embeddings\") \\\n",
    "  .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "def fit_model(epochs):\n",
    "    \n",
    "    # Create the feature extractor using BIO-rBERTa word embeddings\n",
    "    embeddings = RoBertaEmbeddings.pretrained(\"roberta_embeddings_pmc_med_bio_mlm_roberta_large\", \"en\") \\\n",
    "      .setInputCols([\"document\", \"cleanedToken\"]) \\\n",
    "      .setOutputCol(\"embeddings\")\n",
    "    \n",
    "    # Create the text classifier using ClassifierDLApproach.\n",
    "    classifier_dl = ClassifierDLApproach() \\\n",
    "      .setInputCols(['sentence_embeddings']) \\\n",
    "      .setOutputCol('prediction') \\\n",
    "      .setLabelColumn('label') \\\n",
    "      .setBatchSize(comb[\"batchSize\"]) \\\n",
    "      .setMaxEpochs(comb[\"maxEpochs\"]) \\\n",
    "      .setLr(comb[\"lr\"]) \\\n",
    "      .setDropout(comb[\"dropout\"]) \\\n",
    "      .setEnableOutputLogs(True)\n",
    "\n",
    "\n",
    "    # Creating the pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "      document_assembler,\n",
    "      tokenizer,\n",
    "      stops,\n",
    "      embeddings,\n",
    "      sentence_embeddings,\n",
    "      label_indexer,\n",
    "      classifier_dl\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    model_pipeline = pipeline.fit(train)\n",
    "\n",
    "    # Make predictions on the train and test sets\n",
    "    train_predicted = model_pipeline.transform(train).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "    test_predicted = model_pipeline.transform(test).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "\n",
    "    # Initialize the evaluators\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the train set\n",
    "    train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "    train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "    train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score on the test set\n",
    "    test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "    test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "    test_f1 = evaluator_f1.evaluate(test_predicted)\n",
    "\n",
    "    # Create a dictionary with the results\n",
    "    result = {\n",
    "        'Train Precision': train_precision,\n",
    "        'Train Recall': train_recall,\n",
    "        'Train F1 Score': train_f1,\n",
    "        'Test Precision': test_precision,\n",
    "        'Test Recall': test_recall,\n",
    "        'Test F1 Score': test_f1\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(result, index=[0])\n",
    "\n",
    "# Define the hyperparameter options for each model\n",
    "hyperparameter_options = {\n",
    "    'roberta_embeddings_pmc_med_bio_mlm_roberta_large': {\n",
    "            'batchSize': [64],\n",
    "            'dropout': [0.4],\n",
    "            'lr': [0.001, 0.01, 0.1],\n",
    "            'maxEpochs': [20]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Create the results DataFrame combining the metrics and parameter combinations\n",
    "combinations = []\n",
    "for key, options in hyperparameter_options.items():\n",
    "    keys = options.keys()\n",
    "    values = options.values()\n",
    "    param_combinations = [dict(zip(keys, param_values)) for param_values in itertools.product(*values)]\n",
    "    for combination in param_combinations:\n",
    "        combination['model'] = key\n",
    "        combinations.append(combination)\n",
    "\n",
    "dla_results = pd.DataFrame()\n",
    "for comb in combinations:\n",
    "    dla_results = pd.concat([dla_results.reset_index(drop = True), fit_model(comb)], axis = 0)\n",
    "    \n",
    "dla_results = pd.concat([dla_results.reset_index(drop = True), pd.DataFrame(combinations).reset_index(drop = True)], axis = 1, ignore_index=True)\n",
    "\n",
    "new_column_names = {0:'train_acc', 1:'train_rec', 2:'train_f1', 3:'test_acc', 4:'test_rec', 5:'test_f1', 6:'batch_size', 7:'dropout', 8:'lr', 9:'epochs'}\n",
    "dla_results.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "dla_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47082ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "0    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64  \\\n",
       "1    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "2    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "\n",
       "   dropout     lr  epochs                                                10  \n",
       "0      0.4  0.001      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "1      0.4  0.010      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "2      0.4  0.100      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIOroBERTa_results = dla_results\n",
    "BIOroBERTa_results.sort_values(by = [\"test_f1\"], ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b5f41c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'MK9VQ5GAQTRZHK8W',\n",
       "  'HostId': '3i2ZGqLNDcwrAF9uNZrtJkB9sG8aXamKnQkXUaSKGYtBZT/MJqUq+t5ti27+qeWtbjYnoedWHV8NbkwM4UQOAQ==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '3i2ZGqLNDcwrAF9uNZrtJkB9sG8aXamKnQkXUaSKGYtBZT/MJqUq+t5ti27+qeWtbjYnoedWHV8NbkwM4UQOAQ==',\n",
       "   'x-amz-request-id': 'MK9VQ5GAQTRZHK8W',\n",
       "   'date': 'Fri, 07 Jul 2023 18:41:08 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"e8d4f93aff53b1ba2066ddde4356b09e\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e8d4f93aff53b1ba2066ddde4356b09e\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the DataFrame to CSV format in memory.\n",
    "csv_buffer = BIOroBERTa_results.to_csv(index=False).encode()\n",
    "\n",
    "# Create an instance of the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Sepcify file name and route in the S3\n",
    "bucket_name = 'samtfm'\n",
    "file_name = 'binary_BIOroBERTa_results_balanced_S3_total(2).csv'\n",
    "\n",
    "# Uppload file to the S3 bucket\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=bucket_name, Key=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26864faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40813</td>\n",
       "      <td>0.638851</td>\n",
       "      <td>0.498069</td>\n",
       "      <td>0.391498</td>\n",
       "      <td>0.625698</td>\n",
       "      <td>0.481637</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.100</td>\n",
       "      <td>20</td>\n",
       "      <td>roberta_embeddings_pmc_med_bio_mlm_roberta_large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_acc  train_rec  train_f1  test_acc  test_rec   test_f1  batch_size   \n",
       "0    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64  \\\n",
       "1    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "2    0.40813   0.638851  0.498069  0.391498  0.625698  0.481637          64   \n",
       "\n",
       "   dropout     lr  epochs                                                10  \n",
       "0      0.4  0.001      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "1      0.4  0.010      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  \n",
       "2      0.4  0.100      20  roberta_embeddings_pmc_med_bio_mlm_roberta_large  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIOroBERTa_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c21530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee395d7f",
   "metadata": {},
   "source": [
    "## Retraining the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a00b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_en download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[OK!]\n",
      "bert_embeddings_bert_large_uncased_whole_word_masking download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 09:32:48.188690: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/deca51ef69a8_classifier_dl12052074216352787035\n",
      "2023-07-08 09:32:48.289680: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2023-07-08 09:32:48.289733: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/deca51ef69a8_classifier_dl12052074216352787035\n",
      "2023-07-08 09:32:48.808733: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-07-08 09:32:49.890971: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/deca51ef69a8_classifier_dl12052074216352787035\n",
      "2023-07-08 09:32:50.163165: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1974485 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 64 - training_examples: 910 - classes: 2\n",
      "Epoch 1/20 - 0.48s - loss: 8.606682 - acc: 0.7984694 - batches: 15\n",
      "Epoch 2/20 - 0.16s - loss: 6.061836 - acc: 1.0 - batches: 15\n",
      "Epoch 3/20 - 0.11s - loss: 5.2382693 - acc: 1.0 - batches: 15\n",
      "Epoch 4/20 - 0.10s - loss: 4.942123 - acc: 1.0 - batches: 15\n",
      "Epoch 5/20 - 0.10s - loss: 4.716067 - acc: 1.0 - batches: 15\n",
      "Epoch 6/20 - 0.10s - loss: 4.725168 - acc: 1.0 - batches: 15\n",
      "Epoch 7/20 - 0.10s - loss: 4.7121887 - acc: 1.0 - batches: 15\n",
      "Epoch 8/20 - 0.10s - loss: 4.713143 - acc: 1.0 - batches: 15\n",
      "Epoch 9/20 - 0.10s - loss: 4.7089496 - acc: 1.0 - batches: 15\n",
      "Epoch 10/20 - 0.10s - loss: 4.7085724 - acc: 1.0 - batches: 15\n",
      "Epoch 11/20 - 0.10s - loss: 4.7094803 - acc: 1.0 - batches: 15\n",
      "Epoch 12/20 - 0.10s - loss: 4.7127385 - acc: 1.0 - batches: 15\n",
      "Epoch 13/20 - 0.10s - loss: 4.7078156 - acc: 1.0 - batches: 15\n",
      "Epoch 14/20 - 0.10s - loss: 4.7082777 - acc: 1.0 - batches: 15\n",
      "Epoch 15/20 - 0.11s - loss: 4.7084627 - acc: 1.0 - batches: 15\n",
      "Epoch 16/20 - 0.11s - loss: 4.7079277 - acc: 1.0 - batches: 15\n",
      "Epoch 17/20 - 0.10s - loss: 4.703684 - acc: 1.0 - batches: 15\n",
      "Epoch 18/20 - 0.10s - loss: 4.7034397 - acc: 1.0 - batches: 15\n",
      "Epoch 19/20 - 0.11s - loss: 4.702341 - acc: 1.0 - batches: 15\n",
      "Epoch 20/20 - 0.10s - loss: 4.701355 - acc: 1.0 - batches: 15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "# Define the assembler\n",
    "document_assembler = DocumentAssembler().setInputCol('frase_traducida').setOutputCol('document')\n",
    "\n",
    "# Define the word tokenizer\n",
    "tokenizer = Tokenizer().setInputCols(['document']).setOutputCol('token')\n",
    "\n",
    "# Define the stopword remover\n",
    "stops = StopWordsCleaner.pretrained()\\\n",
    ".setInputCols(\"token\")\\\n",
    ".setOutputCol(\"cleanedToken\")\n",
    "\n",
    "# Create the feature extractor using BERT word embeddings\n",
    "embeddings = BertEmbeddings.pretrained(\"bert_embeddings_bert_large_uncased_whole_word_masking\", \"en\") \\\n",
    "  .setInputCols([\"document\", \"cleanedToken\"]) \\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "# Create the sentence embeddings feature extractor\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "  .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"sentence_embeddings\") \\\n",
    "  .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# Define a function to convert labels to indices and use it to fit the data\n",
    "label_indexer = StringIndexer(\n",
    "  inputCol = 'contiene_indicador', \n",
    "  outputCol = 'label').fit(frases)\n",
    "\n",
    "    \n",
    "# Create the text classifier using ClassifierDLApproach.\n",
    "classifier_dl = ClassifierDLApproach() \\\n",
    "  .setInputCols(['sentence_embeddings']) \\\n",
    "  .setOutputCol('prediction') \\\n",
    "  .setLabelColumn('label') \\\n",
    "  .setBatchSize(64) \\\n",
    "  .setMaxEpochs(20) \\\n",
    "  .setLr(0.001) \\\n",
    "  .setDropout(0) \\\n",
    "  .setEnableOutputLogs(True)\n",
    "\n",
    "\n",
    "# Creating the pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "  document_assembler,\n",
    "  tokenizer,\n",
    "  stops,\n",
    "  embeddings,\n",
    "  sentence_embeddings,\n",
    "  label_indexer,\n",
    "  classifier_dl\n",
    "])\n",
    "    \n",
    "# Train the model\n",
    "model_pipeline = pipeline.fit(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552056c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the train and test sets\n",
    "train_predicted = model_pipeline.transform(frases).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "test_predicted = model_pipeline.transform(unseen).selectExpr(\"label\", \"double(prediction.result[0]) as prediction\")\n",
    "\n",
    "# Initialize the evaluators\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "\n",
    "# Calculate precision, recall, and F1 score on the train set\n",
    "train_precision = evaluator_precision.evaluate(train_predicted)\n",
    "train_recall = evaluator_recall.evaluate(train_predicted)\n",
    "train_f1 = evaluator_f1.evaluate(train_predicted)\n",
    "\n",
    "# Calculate precision, recall, and F1 score on the test set\n",
    "test_precision = evaluator_precision.evaluate(test_predicted)\n",
    "test_recall = evaluator_recall.evaluate(test_predicted)\n",
    "test_f1 = evaluator_f1.evaluate(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52cb81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with the results\n",
    "result = {\n",
    "    'Train Precision': train_precision,\n",
    "    'Train Recall': train_recall,\n",
    "    'Train F1 Score': train_f1,\n",
    "    'Test Precision': test_precision,\n",
    "    'Test Recall': test_recall,\n",
    "    'Test F1 Score': test_f1\n",
    "}\n",
    "\n",
    "# Calculate confusion matrix for test set\n",
    "y_true = test_predicted.select(\"label\").toPandas()\n",
    "y_pred = test_predicted.select(\"prediction\").toPandas()\n",
    "\n",
    "# Invert the values of the column\n",
    "mapeo = {0: 1, 1: 0}\n",
    "y_true['label'] = y_true['label'].map(mapeo)\n",
    "y_pred['prediction'] = y_pred['prediction'].map(mapeo)\n",
    "\n",
    "result = pd.DataFrame(result, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ae986",
   "metadata": {},
   "source": [
    "### Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c2ac230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Train F1 Score</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.936897</td>\n",
       "      <td>0.932692</td>\n",
       "      <td>0.933868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Precision  Train Recall  Train F1 Score  Test Precision  Test Recall   \n",
       "0         0.991209      0.991209        0.991209        0.936897     0.932692  \\\n",
       "\n",
       "   Test F1 Score  \n",
       "0       0.933868  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279b817",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50ae445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_test = confusion_matrix(y_true, y_pred)\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3094cf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  24   2\n",
       "1   5  73"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "115ae295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a heatmap plot of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt='d', cmap='Oranges')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Change the labels of the x and y axes\n",
    "plt.xticks([0.5, 1.5], ['Does not contain Indicator', 'Contains Indicator'])\n",
    "plt.yticks([0.5, 1.5], ['Does not contain Indicator', 'Contains Indicator'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76edab",
   "metadata": {},
   "source": [
    "### Example predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4cc3d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unseen = pd.read_csv(file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39f7cffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "muestra_df = pd.concat([unseen.frase, y_true, y_pred], axis = 1)\n",
    "muestra_df.columns = ['Testimony phrase', 'Contains indicator', 'Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "313cb755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  \n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testimony phrase</th>\n",
       "      <th>Contains indicator</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>por ello nunca deje de trabajar yo siempre est...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y al siguiente día iba a trabajar y ese es mi ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Hola, me llamo Marta y tengo 16 años.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hace 10 años me diagnosticaron un tumor en mi ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debido al tumor estuve todo el año ingresada y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>De eso ya me recuperé, rehice mi vida y volví ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>En diciembre del año pasado me volvió a salir ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>, pero esta vez los traumatólogos han podido s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Actualmente estoy en tratamiento con quimio.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>La recuperación es lenta aunque positiva</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Testimony phrase  Contains indicator   \n",
       "0  por ello nunca deje de trabajar yo siempre est...                   1  \\\n",
       "1  y al siguiente día iba a trabajar y ese es mi ...                   1   \n",
       "2             “Hola, me llamo Marta y tengo 16 años.                   0   \n",
       "3  Hace 10 años me diagnosticaron un tumor en mi ...                   1   \n",
       "4  Debido al tumor estuve todo el año ingresada y...                   0   \n",
       "5  De eso ya me recuperé, rehice mi vida y volví ...                   1   \n",
       "6  En diciembre del año pasado me volvió a salir ...                   1   \n",
       "7  , pero esta vez los traumatólogos han podido s...                   1   \n",
       "8       Actualmente estoy en tratamiento con quimio.                   0   \n",
       "9           La recuperación es lenta aunque positiva                   1   \n",
       "\n",
       "   Prediction  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "5           1  \n",
       "6           1  \n",
       "7           1  \n",
       "8           0  \n",
       "9           1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra_df[6:16].reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
